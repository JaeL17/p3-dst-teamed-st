{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"TRADE_Transformer_segment.ipynb","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"847649174379430eb6e912c059debaf9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6d6604bdd4c141ac994d57b476a11e9d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8bde36efeb524ff88f001e3dde5a6175","IPY_MODEL_8230b957f1364ef0932849d53c5be973"]}},"6d6604bdd4c141ac994d57b476a11e9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8bde36efeb524ff88f001e3dde5a6175":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f4757607eead438c8feab7c1619c33a1","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":263327,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":263327,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dc19221c112a4bfaaf5320068f72ad26"}},"8230b957f1364ef0932849d53c5be973":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3eeab906ddbb4f93ba81aac75c9bcf81","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 263k/263k [00:00&lt;00:00, 274kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ddee06bc79b4d47ab15f84446886a3b"}},"f4757607eead438c8feab7c1619c33a1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dc19221c112a4bfaaf5320068f72ad26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3eeab906ddbb4f93ba81aac75c9bcf81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ddee06bc79b4d47ab15f84446886a3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04a5bbcb21ae460caf3e89094463e300":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e581385ff9fb4054a39293809fdbfaf7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3cd4081e71c44c6e8a3091800bac9a4c","IPY_MODEL_bae1c2e91a714c1da1769bff3b8b6f49"]}},"e581385ff9fb4054a39293809fdbfaf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3cd4081e71c44c6e8a3091800bac9a4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ab69cda5135a448c92280a8af9b77d7f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":124,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":124,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e3afe715393415390521a291f71608b"}},"bae1c2e91a714c1da1769bff3b8b6f49":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfea2115bede4b2db084fd46867ce7ed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 124/124 [00:00&lt;00:00, 162B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2828d85275ce40e3b3d8653281399670"}},"ab69cda5135a448c92280a8af9b77d7f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e3afe715393415390521a291f71608b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfea2115bede4b2db084fd46867ce7ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2828d85275ce40e3b3d8653281399670":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c9cccd25e6e4079aa29f12e8f4aa486":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6a54135610ae46a3b39a9420d41ba18f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0b29efa8bd2345de8cb2dd5167d61335","IPY_MODEL_690b3ce07ddb454aa1a9b6c396e1d7eb"]}},"6a54135610ae46a3b39a9420d41ba18f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b29efa8bd2345de8cb2dd5167d61335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2cfd8bb7411447958133c62c1e8f12d6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":288,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":288,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_41488f29982e44eba6fa0fc4271f5fbc"}},"690b3ce07ddb454aa1a9b6c396e1d7eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e8d9e2ee9c8249969db580d71c45153d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 288/288 [00:00&lt;00:00, 1.00kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8613bb28f1a544738f98eb143e91963c"}},"2cfd8bb7411447958133c62c1e8f12d6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"41488f29982e44eba6fa0fc4271f5fbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8d9e2ee9c8249969db580d71c45153d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8613bb28f1a544738f98eb143e91963c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14fb0850ee894ccb9a57f45c8ef75c32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_39fd9423de8e4e1e87f63bd172b04b6a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fae1e6bac6c5491d9aeaa7f171ac68d2","IPY_MODEL_e0cdfac3f78545cf94b7428ca22a6748"]}},"39fd9423de8e4e1e87f63bd172b04b6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fae1e6bac6c5491d9aeaa7f171ac68d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_92c08e05abd8420fb2e3a187a0282c75","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":434,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":434,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11c5a4e13968494998cff84276c6e13a"}},"e0cdfac3f78545cf94b7428ca22a6748":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1df28a81672e4f1680d9eb3f87ef42e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 434/434 [00:00&lt;00:00, 1.32kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_61535c41e1db4df3830227e7cb01d27e"}},"92c08e05abd8420fb2e3a187a0282c75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11c5a4e13968494998cff84276c6e13a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1df28a81672e4f1680d9eb3f87ef42e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"61535c41e1db4df3830227e7cb01d27e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ae62d96fd3f64b67a56989784e213821":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7ffad69e2c4040c1bcaf7e490fb2f3a3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bab3f1878729460ea2521e0131aa80d8","IPY_MODEL_429e3f10eca446b89cd8e420c4b489b8"]}},"7ffad69e2c4040c1bcaf7e490fb2f3a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bab3f1878729460ea2521e0131aa80d8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1f5a13b3ecda4f2c958070e834993362","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":284118515,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":284118515,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9e3043b349b42d18ad30086a80797e7"}},"429e3f10eca446b89cd8e420c4b489b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9183063488ce41a3accf31149539b68d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 284M/284M [00:10&lt;00:00, 28.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_71bcd1ecdf85485299064f3a51643486"}},"1f5a13b3ecda4f2c958070e834993362":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d9e3043b349b42d18ad30086a80797e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9183063488ce41a3accf31149539b68d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"71bcd1ecdf85485299064f3a51643486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUBti5G41WV0","executionInfo":{"status":"ok","timestamp":1621500597571,"user_tz":-540,"elapsed":27944,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"30ba2898-edff-4272-f331-df0ef7305039"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eTBNo6R-1WSv","executionInfo":{"status":"ok","timestamp":1621500598059,"user_tz":-540,"elapsed":28424,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["import os\n","os.chdir('/content/drive/MyDrive/Stage3/code')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbCx8zyW1ZoN","executionInfo":{"status":"ok","timestamp":1621500605641,"user_tz":-540,"elapsed":35686,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"ab591a7a-8c01-48f1-c0b1-59192a19adc2"},"source":["!pip install transformers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 8.6MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 46.3MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 43.6MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ITO1erJr04W8","executionInfo":{"status":"ok","timestamp":1621500611554,"user_tz":-540,"elapsed":41581,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["import json\n","import random\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","from transformers import BertModel, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup\n","from data_utils import (\n","    load_dataset, \n","    get_examples_from_dialogues, \n","    convert_state_dict, \n","    DSTInputExample, \n","    OpenVocabDSTFeature, \n","    DSTPreprocessor, \n","    WOSDataset)\n","    \n","from inference import inference\n","from evaluation import _evaluation\n","from data_utils import set_seed"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1Tw9bZT04XC"},"source":["## Data loading"]},{"cell_type":"code","metadata":{"id":"-vdfArIOzVCy","executionInfo":{"status":"ok","timestamp":1621500613711,"user_tz":-540,"elapsed":2152,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["set_seed(42)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O-6Xn5G504XD","executionInfo":{"status":"ok","timestamp":1621500617646,"user_tz":-540,"elapsed":6073,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"06e506da-4091-4607-a92e-9f8389456eb2"},"source":["train_data_file = \"/content/drive/MyDrive/Stage3/input/data/train_dataset/train_dials.json\"\n","slot_meta = json.load(open(\"/content/drive/MyDrive/Stage3/input/data/train_dataset/slot_meta.json\"))\n","ontology = json.load(open(\"/content/drive/MyDrive/Stage3/input/data/train_dataset/ontology.json\"))\n","train_data, dev_data, dev_labels = load_dataset(train_data_file)\n","\n","train_examples = get_examples_from_dialogues(train_data,\n","                                             user_first=False,\n","                                             dialogue_level=False)\n","dev_examples = get_examples_from_dialogues(dev_data,\n","                                           user_first=False,\n","                                           dialogue_level=False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|██████████| 6301/6301 [00:00<00:00, 9419.52it/s]\n","100%|██████████| 699/699 [00:00<00:00, 13502.10it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6C9sqEXz04XE","executionInfo":{"status":"ok","timestamp":1621500617647,"user_tz":-540,"elapsed":5681,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"eecaaea5-8f68-4bbf-ecb7-5a77ceff0fbe"},"source":["print(len(train_examples))\n","print(len(dev_examples))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["46170\n","5075\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hk2bVKMH04XE"},"source":["## TRADE Preprocessor "]},{"cell_type":"markdown","metadata":{"id":"SaR5NuDp04XE"},"source":["기존의 GRU 기반의 인코더를 BERT-based Encoder로 바꿀 준비를 합시다.\n","\n","1. 현재 `_convert_example_to_feature`에서는 `max_seq_length`를 핸들하고 있지 않습니다. `input_id`와 `segment_id`가 `max_seq_length`를 넘어가면 좌측부터 truncate시키는 코드를 삽입하세요.\n","\n","2. hybrid approach에서 얻은 교훈을 바탕으로 gate class를 3개에서 5개로 늘려봅시다.\n","    - `gating2id`를 수정하세요\n","    - 이에 따른 `recover_state`를 수정하세요.\n","    \n","3. word dropout을 구현하세요."]},{"cell_type":"code","metadata":{"id":"Bo89P9d304XF","executionInfo":{"status":"ok","timestamp":1621500617648,"user_tz":-540,"elapsed":1451,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["class TRADEPreprocessor(DSTPreprocessor):\n","    def __init__(\n","        self,\n","        slot_meta,\n","        src_tokenizer,\n","        trg_tokenizer=None,\n","        ontology=None,\n","        max_seq_length=512,\n","    ):\n","        self.slot_meta = slot_meta\n","        self.src_tokenizer = src_tokenizer\n","        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n","        self.ontology = ontology\n","        self.gating2id = {\"none\": 0, \"dontcare\": 1, \"yes\": 2, \"no\": 3, \"ptr\": 4}\n","        self.id2gating = {v: k for k, v in self.gating2id.items()}\n","        self.max_seq_length = max_seq_length\n","\n","    def _convert_example_to_feature(self, example):\n","        dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n","\n","        input_id = self.src_tokenizer.encode(dialogue_context, add_special_tokens=False)\n","        max_length = self.max_seq_length - 2\n","        if len(input_id) > max_length:\n","            gap = len(input_id) - max_length\n","            input_id = input_id[gap:]\n","\n","        input_id = (\n","            [self.src_tokenizer.cls_token_id]\n","            + input_id\n","            + [self.src_tokenizer.sep_token_id]\n","        )\n","        segment_id = [0] * (len(example.context_turns) +2) + [1] * (len(example.current_turn) +1)\n","\n","\n","        target_ids = []\n","        gating_id = []\n","        if not example.label:\n","            example.label = []\n","\n","        state = convert_state_dict(example.label)\n","        for slot in self.slot_meta:\n","            value = state.get(slot, \"none\")\n","            target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n","                self.trg_tokenizer.sep_token_id\n","            ]\n","            target_ids.append(target_id)\n","            gating_id.append(self.gating2id.get(value, self.gating2id[\"ptr\"]))\n","        target_ids = self.pad_ids(target_ids, self.trg_tokenizer.pad_token_id)\n","        return OpenVocabDSTFeature(\n","            example.guid, input_id, segment_id, gating_id, target_ids\n","        )\n","\n","    def convert_examples_to_features(self, examples):\n","        return list(map(self._convert_example_to_feature, examples))\n","\n","    def recover_state(self, gate_list, gen_list):\n","        assert len(gate_list) == len(self.slot_meta)\n","        assert len(gen_list) == len(self.slot_meta)\n","\n","        recovered = []\n","        for slot, gate, value in zip(self.slot_meta, gate_list, gen_list):\n","            if self.id2gating[gate] == \"none\":\n","                continue\n","\n","            if self.id2gating[gate] in [\"dontcare\", \"yes\", \"no\"]:\n","                recovered.append(\"%s-%s\" % (slot, self.id2gating[gate]))\n","                continue\n","\n","            token_id_list = []\n","            for id_ in value:\n","                if id_ in self.trg_tokenizer.all_special_ids:\n","                    break\n","\n","                token_id_list.append(id_)\n","            value = self.trg_tokenizer.decode(token_id_list, skip_special_tokens=True)\n","\n","            if value == \"none\":\n","                continue\n","\n","            recovered.append(\"%s-%s\" % (slot, value))\n","        return recovered\n","\n","    def collate_fn(self, batch):\n","        guids = [b.guid for b in batch]\n","        input_ids = torch.LongTensor(\n","            self.pad_ids([b.input_id for b in batch], self.src_tokenizer.pad_token_id)\n","        )\n","        segment_ids = torch.LongTensor(\n","            self.pad_ids([b.segment_id for b in batch], self.src_tokenizer.pad_token_id)\n","        )\n","        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n","\n","        gating_ids = torch.LongTensor([b.gating_id for b in batch])\n","        target_ids = self.pad_id_of_matrix(\n","            [torch.LongTensor(b.target_ids) for b in batch],\n","            self.trg_tokenizer.pad_token_id,\n","        )\n","        return input_ids, segment_ids, input_masks, gating_ids, target_ids, guids"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wd47XExT04XF"},"source":["## Convert_Examples_to_Features "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["847649174379430eb6e912c059debaf9","6d6604bdd4c141ac994d57b476a11e9d","8bde36efeb524ff88f001e3dde5a6175","8230b957f1364ef0932849d53c5be973","f4757607eead438c8feab7c1619c33a1","dc19221c112a4bfaaf5320068f72ad26","3eeab906ddbb4f93ba81aac75c9bcf81","3ddee06bc79b4d47ab15f84446886a3b","04a5bbcb21ae460caf3e89094463e300","e581385ff9fb4054a39293809fdbfaf7","3cd4081e71c44c6e8a3091800bac9a4c","bae1c2e91a714c1da1769bff3b8b6f49","ab69cda5135a448c92280a8af9b77d7f","1e3afe715393415390521a291f71608b","bfea2115bede4b2db084fd46867ce7ed","2828d85275ce40e3b3d8653281399670","6c9cccd25e6e4079aa29f12e8f4aa486","6a54135610ae46a3b39a9420d41ba18f","0b29efa8bd2345de8cb2dd5167d61335","690b3ce07ddb454aa1a9b6c396e1d7eb","2cfd8bb7411447958133c62c1e8f12d6","41488f29982e44eba6fa0fc4271f5fbc","e8d9e2ee9c8249969db580d71c45153d","8613bb28f1a544738f98eb143e91963c"]},"id":"zOjho3J404XG","executionInfo":{"status":"ok","timestamp":1621501016672,"user_tz":-540,"elapsed":399987,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"1c9a291a-5a34-48a5-e8f8-6696306cc92d"},"source":["tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n","processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)\n","\n","train_features = processor.convert_examples_to_features(train_examples)\n","dev_features = processor.convert_examples_to_features(dev_examples)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"847649174379430eb6e912c059debaf9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263327.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04a5bbcb21ae460caf3e89094463e300","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=124.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c9cccd25e6e4079aa29f12e8f4aa486","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=288.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFNdbCsB04XG","executionInfo":{"status":"ok","timestamp":1621501016673,"user_tz":-540,"elapsed":399819,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"835348f5-3de7-4bea-8e53-e6be87768814"},"source":["print(len(train_features))\n","print(len(dev_features))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["46170\n","5075\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ovQOZ9Sz04XH"},"source":["# Model "]},{"cell_type":"markdown","metadata":{"id":"gaivCGee04XH"},"source":["1. `GRUEncoder`를 `BertModel`로 교체하세요. 이에 따라 `tie_weight` 함수가 수정되어야 합니다."]},{"cell_type":"code","metadata":{"id":"A7M4oZ1w04XH","executionInfo":{"status":"ok","timestamp":1621501016674,"user_tz":-540,"elapsed":398914,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["class TRADE(nn.Module):\n","    def __init__(self, config, slot_vocab, slot_meta, pad_idx=0):\n","        super(TRADE, self).__init__()\n","        self.slot_meta = slot_meta\n","        if config.model_name_or_path:\n","            self.encoder = BertModel.from_pretrained(config.model_name_or_path)\n","        else:\n","            self.encoder = BertModel(config)\n","            \n","        self.decoder = SlotGenerator(\n","            config.vocab_size,\n","            config.hidden_size,\n","            config.hidden_dropout_prob,\n","            config.n_gate,\n","            None,\n","            pad_idx,\n","        )\n","        \n","        # init for only subword embedding\n","        self.decoder.set_slot_idx(slot_vocab)\n","        self.tie_weight()\n","\n","    def tie_weight(self):\n","        self.decoder.embed.weight = self.encoder.embeddings.word_embeddings.weight\n","\n","    def forward(self, input_ids, token_type_ids, attention_mask=None, max_len=10, teacher=None):\n","\n","        encoder_outputs, pooled_output = self.encoder(input_ids=input_ids,return_dict = False)\n","        all_point_outputs, all_gate_outputs = self.decoder(\n","            input_ids,\n","            encoder_outputs,\n","            pooled_output.unsqueeze(0), \n","            attention_mask, \n","            max_len, \n","            teacher\n","        )\n","\n","        return all_point_outputs, all_gate_outputs\n","    \n","class SlotGenerator(nn.Module):\n","    def __init__(\n","        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n","    ):\n","        super(SlotGenerator, self).__init__()\n","        self.pad_idx = pad_idx\n","        \n","        # 전체 보캡에 대해\n","        self.vocab_size = vocab_size\n","        \n","        \n","        self.embed = nn.Embedding(\n","            vocab_size, hidden_size, padding_idx=pad_idx\n","        )  # shared with encoder\n","\n","        if proj_dim:\n","            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n","        else:\n","            self.proj_layer = None\n","        self.hidden_size = proj_dim if proj_dim else hidden_size\n","\n","        \n","        \n","        \n","        #self.gru = nn.GRU(\n","        #    self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n","        #)\n","        self.decoder_layer = nn.TransformerDecoderLayer(d_model=self.hidden_size, nhead=4)\n","        self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n","\n","        self.n_gate = n_gate\n","        self.dropout = nn.Dropout(dropout)\n","        self.w_gen = nn.Linear(self.hidden_size * 3, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n","\n","    def set_slot_idx(self, slot_vocab_idx):\n","        whole = []\n","        \n","        #slot_vocab_idx 중 가장 긴거\n","        max_length = max(map(len, slot_vocab_idx))\n","        for idx in slot_vocab_idx:\n","            if len(idx) < max_length:\n","                gap = max_length - len(idx)\n","                idx.extend([self.pad_idx] * gap)\n","            whole.append(idx)\n","            \n","        #결국 whole == sumbt에서 slotlookup\n","        self.slot_embed_idx = whole  # torch.LongTensor(whole)\n","\n","    def embedding(self, x):\n","        x = self.embed(x)\n","        if self.proj_layer:\n","            x = self.proj_layer(x)\n","        return x\n","\n","    def forward(\n","        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n","    ):\n","        input_masks = input_masks.ne(1)\n","        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n","        # J,2\n","        batch_size = encoder_output.size(0)\n","        \n","        slot = torch.LongTensor(self.slot_embed_idx).to(input_ids.device)  ## J, N, d\n","        slot_e = torch.sum(self.embedding(slot), 1)  # J,d\n","        \n","        J = slot_e.size(0)\n","\n","        all_point_outputs = torch.zeros(batch_size, J, max_len, self.vocab_size).to(\n","            input_ids.device\n","        )\n","        \n","        # Parallel Decoding\n","        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n","        hidden = hidden.repeat_interleave(J, dim=1)\n","        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n","        input_ids = input_ids.repeat_interleave(J, dim=0)\n","        input_masks = input_masks.repeat_interleave(J, dim=0)\n","        \n","        \n","        for k in range(max_len):\n","            w = self.dropout(w)\n","            #_, hidden = self.gru(w, hidden)  # 1,B,D\n","            hidden = self.transformer(hidden,w)\n","\n","            # B,T,D * B,D,1 => B,T\n","            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n","            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e9)\n","            attn_history = F.softmax(attn_e, -1)  # B,T\n","\n","            if self.proj_layer:\n","                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n","            else:\n","                hidden_proj = hidden\n","\n","            # B,D * D,V => B,V\n","            attn_v = torch.matmul(\n","                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n","            )  # B,V\n","            attn_vocab = F.softmax(attn_v, -1)\n","\n","            # B,1,T * B,T,D => B,1,D\n","            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n","            p_gen = self.sigmoid(\n","                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n","            )  # B,1\n","            p_gen = p_gen.squeeze(-1)\n","\n","            p_context_ptr = torch.zeros_like(attn_vocab).to(input_ids.device)\n","            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n","            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n","            _, w_idx = p_final.max(-1)\n","\n","            if teacher is not None:\n","                w = self.embedding(teacher[:, :, k]).transpose(0, 1).reshape(batch_size * J, 1, -1)\n","            else:\n","                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n","            if k == 0:\n","                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n","                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n","            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n","\n","        return all_point_outputs, all_gate_outputs"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XdLS3jkA04XI"},"source":["# 모델 및 데이터 로더 정의"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["14fb0850ee894ccb9a57f45c8ef75c32","39fd9423de8e4e1e87f63bd172b04b6a","fae1e6bac6c5491d9aeaa7f171ac68d2","e0cdfac3f78545cf94b7428ca22a6748","92c08e05abd8420fb2e3a187a0282c75","11c5a4e13968494998cff84276c6e13a","1df28a81672e4f1680d9eb3f87ef42e9","61535c41e1db4df3830227e7cb01d27e","ae62d96fd3f64b67a56989784e213821","7ffad69e2c4040c1bcaf7e490fb2f3a3","bab3f1878729460ea2521e0131aa80d8","429e3f10eca446b89cd8e420c4b489b8","1f5a13b3ecda4f2c958070e834993362","d9e3043b349b42d18ad30086a80797e7","9183063488ce41a3accf31149539b68d","71bcd1ecdf85485299064f3a51643486"]},"id":"-MYTPvu004XI","executionInfo":{"status":"ok","timestamp":1621501029336,"user_tz":-540,"elapsed":410533,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"cad6da09-a852-4bd7-88dd-8782c406cf51"},"source":["slot_vocab = []\n","for slot in slot_meta:\n","    slot_vocab.append(\n","        tokenizer.encode(slot.replace('-', ' '),\n","                         add_special_tokens=False)\n","    )\n","    \n","config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n","config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n","config.n_gate = len(processor.gating2id)\n","config.proj_dim = None\n","model = TRADE(config, slot_vocab, slot_meta)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14fb0850ee894ccb9a57f45c8ef75c32","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=434.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae62d96fd3f64b67a56989784e213821","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=284118515.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ksvFxR-h04XI","executionInfo":{"status":"ok","timestamp":1621501029337,"user_tz":-540,"elapsed":408789,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","train_data = WOSDataset(train_features)\n","train_sampler = RandomSampler(train_data)\n","train_loader = DataLoader(train_data, batch_size=8, sampler=train_sampler, collate_fn=processor.collate_fn)\n","\n","dev_data = WOSDataset(dev_features)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AVYxBaXE04XJ"},"source":["# Optimizer & Scheduler 선언"]},{"cell_type":"code","metadata":{"id":"NmDmrigU04XJ","executionInfo":{"status":"ok","timestamp":1621501036216,"user_tz":-540,"elapsed":411204,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["n_epochs = 50\n","no_decay = [\"bias\", \"LayerNorm.weight\"]\n","optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.01,\n","        },\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n","            \"weight_decay\": 0.0,\n","        },\n","    ]\n","\n","t_total = len(train_loader) * n_epochs\n","optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=0.1, num_training_steps=t_total\n",")\n","teacher_forcing = 0.5\n","model.to(device)\n","\n","def masked_cross_entropy_for_value(logits, target, pad_idx=0):\n","    mask = target.ne(pad_idx)\n","    logits_flat = logits.view(-1, logits.size(-1))\n","    log_probs_flat = torch.log(logits_flat)\n","    target_flat = target.view(-1, 1)\n","    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n","    losses = losses_flat.view(*target.size())\n","    losses = losses * mask.float()\n","    loss = losses.sum() / (mask.sum().float())\n","    return loss\n","\n","loss_fnc_1 = masked_cross_entropy_for_value  # generation\n","loss_fnc_2 = nn.CrossEntropyLoss()  # gating"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0GK3Z8z04XJ"},"source":["## Train"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"mrWnCWwC04XJ","outputId":"62c0f8c4-115f-497c-9cf9-3e08a6754773"},"source":["fffff\n","best_score = 0\n","cnt = 0\n","for epoch in range(50):\n","    batch_loss = []\n","    model.train()\n","    for step, batch in enumerate(train_loader):\n","        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [b.to(device) if not isinstance(b, list) else b for b in batch]\n","        if teacher_forcing > 0.0 and random.random() < teacher_forcing:\n","            tf = target_ids\n","        else:\n","            tf = None\n","\n","        all_point_outputs, all_gate_outputs = model(input_ids, segment_ids, input_masks, target_ids.size(-1))  # gt - length (generation)\n","        loss_1 = loss_fnc_1(all_point_outputs.contiguous(), target_ids.contiguous().view(-1))\n","        loss_2 = loss_fnc_2(all_gate_outputs.contiguous().view(-1, 5), gating_ids.contiguous().view(-1))\n","        loss = loss_1 + loss_2\n","        batch_loss.append(loss.item())\n","\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","        if step % 100 == 0:\n","            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n","       \n","    predictions = inference(model, dev_loader, processor, device)\n","    eval_result = _evaluation(predictions, dev_labels, slot_meta)\n","    score = eval_result['joint_goal_accuracy']\n","    if score > best_score:\n","        cnt = 0\n","        best_score = score\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/Stage3/model/trade_transformer_best.pt\")\n","    \n","    #else:\n","    #    cnt += 1\n","    #    if cnt == 5:\n","    #        print('Early stop! Epoch:',str(epoch))\n","    #        break\n","    \n","    for k, v in eval_result.items():\n","        print(f\"{k}: {v}\")\n","torch.save(model.state_dict(), \"/content/drive/MyDrive/Stage3/model/trade_transformer_50.pt\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0/50] [0/5772] 14.580219\n","[0/50] [100/5772] 1.788384\n","[0/50] [200/5772] 1.320970\n","[0/50] [300/5772] 1.062520\n","[0/50] [400/5772] 1.172823\n","[0/50] [500/5772] 1.033173\n","[0/50] [600/5772] 0.942167\n","[0/50] [700/5772] 0.555394\n","[0/50] [800/5772] 0.859395\n","[0/50] [900/5772] 0.593315\n","[0/50] [1000/5772] 0.490033\n","[0/50] [1100/5772] 0.735464\n","[0/50] [1200/5772] 0.363320\n","[0/50] [1300/5772] 0.498603\n","[0/50] [1400/5772] 0.307671\n","[0/50] [1500/5772] 0.320645\n","[0/50] [1600/5772] 0.396256\n","[0/50] [1700/5772] 0.316367\n","[0/50] [1800/5772] 0.248857\n","[0/50] [1900/5772] 0.446112\n","[0/50] [2000/5772] 0.400615\n","[0/50] [2100/5772] 0.309392\n","[0/50] [2200/5772] 0.197964\n","[0/50] [2300/5772] 0.239243\n","[0/50] [2400/5772] 0.372462\n","[0/50] [2500/5772] 0.225404\n","[0/50] [2600/5772] 0.330557\n","[0/50] [2700/5772] 0.317234\n","[0/50] [2800/5772] 0.299415\n","[0/50] [2900/5772] 0.412460\n","[0/50] [3000/5772] 0.271218\n","[0/50] [3100/5772] 0.143259\n","[0/50] [3200/5772] 0.230600\n","[0/50] [3300/5772] 0.459866\n","[0/50] [3400/5772] 0.209698\n","[0/50] [3500/5772] 0.338970\n","[0/50] [3600/5772] 0.260012\n","[0/50] [3700/5772] 0.133884\n","[0/50] [3800/5772] 0.237133\n","[0/50] [3900/5772] 0.175934\n","[0/50] [4000/5772] 0.244576\n","[0/50] [4100/5772] 0.276223\n","[0/50] [4200/5772] 0.435949\n","[0/50] [4300/5772] 0.202985\n","[0/50] [4400/5772] 0.203250\n","[0/50] [4500/5772] 0.169776\n","[0/50] [4600/5772] 0.160307\n","[0/50] [4700/5772] 0.193903\n","[0/50] [4800/5772] 0.286502\n","[0/50] [4900/5772] 0.255386\n","[0/50] [5000/5772] 0.238793\n","[0/50] [5100/5772] 0.240651\n","[0/50] [5200/5772] 0.367914\n","[0/50] [5300/5772] 0.098927\n","[0/50] [5400/5772] 0.187073\n","[0/50] [5500/5772] 0.186644\n","[0/50] [5600/5772] 0.253059\n","[0/50] [5700/5772] 0.157253\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 635/635 [03:31<00:00,  3.00it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'joint_goal_accuracy': 0.21517241379310345, 'turn_slot_accuracy': 0.95732019704435, 'turn_slot_f1': 0.8160748145418041}\n","joint_goal_accuracy: 0.21517241379310345\n","turn_slot_accuracy: 0.95732019704435\n","turn_slot_f1: 0.8160748145418041\n","[1/50] [0/5772] 0.107206\n","[1/50] [100/5772] 0.113113\n","[1/50] [200/5772] 0.238200\n","[1/50] [300/5772] 0.167443\n","[1/50] [400/5772] 0.179293\n","[1/50] [500/5772] 0.159053\n","[1/50] [600/5772] 0.206386\n","[1/50] [700/5772] 0.181444\n","[1/50] [800/5772] 0.184207\n","[1/50] [900/5772] 0.178955\n","[1/50] [1000/5772] 0.069459\n","[1/50] [1100/5772] 0.305747\n","[1/50] [1200/5772] 0.239655\n","[1/50] [1300/5772] 0.113650\n","[1/50] [1400/5772] 0.146167\n","[1/50] [1500/5772] 0.060224\n","[1/50] [1600/5772] 0.101877\n","[1/50] [1700/5772] 0.279358\n","[1/50] [1800/5772] 0.102700\n","[1/50] [1900/5772] 0.045201\n","[1/50] [2000/5772] 0.095045\n","[1/50] [2100/5772] 0.067352\n","[1/50] [2200/5772] 0.078987\n","[1/50] [2300/5772] 0.270099\n","[1/50] [2400/5772] 0.193313\n","[1/50] [2500/5772] 0.052020\n","[1/50] [2600/5772] 0.187921\n","[1/50] [2700/5772] 0.139452\n","[1/50] [2800/5772] 0.265065\n","[1/50] [2900/5772] 0.067672\n","[1/50] [3000/5772] 0.052601\n","[1/50] [3100/5772] 0.159143\n","[1/50] [3200/5772] 0.028714\n","[1/50] [3300/5772] 0.104042\n","[1/50] [3400/5772] 0.140899\n","[1/50] [3500/5772] 0.048335\n","[1/50] [3600/5772] 0.096380\n","[1/50] [3700/5772] 0.083492\n","[1/50] [3800/5772] 0.036207\n","[1/50] [3900/5772] 0.091456\n","[1/50] [4000/5772] 0.116916\n","[1/50] [4100/5772] 0.186044\n","[1/50] [4200/5772] 0.090392\n","[1/50] [4300/5772] 0.077267\n","[1/50] [4400/5772] 0.045429\n","[1/50] [4500/5772] 0.159097\n","[1/50] [4600/5772] 0.094061\n","[1/50] [4700/5772] 0.062956\n","[1/50] [4800/5772] 0.089458\n","[1/50] [4900/5772] 0.045996\n","[1/50] [5000/5772] 0.110626\n","[1/50] [5100/5772] 0.061930\n","[1/50] [5200/5772] 0.050552\n","[1/50] [5300/5772] 0.098464\n","[1/50] [5400/5772] 0.099487\n","[1/50] [5500/5772] 0.071021\n","[1/50] [5600/5772] 0.082132\n","[1/50] [5700/5772] 0.152605\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 635/635 [03:32<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'joint_goal_accuracy': 0.4250246305418719, 'turn_slot_accuracy': 0.9760525451560025, 'turn_slot_f1': 0.8960537621226483}\n","joint_goal_accuracy: 0.4250246305418719\n","turn_slot_accuracy: 0.9760525451560025\n","turn_slot_f1: 0.8960537621226483\n","[2/50] [0/5772] 0.131891\n","[2/50] [100/5772] 0.119986\n","[2/50] [200/5772] 0.066515\n","[2/50] [300/5772] 0.087678\n","[2/50] [400/5772] 0.080316\n","[2/50] [500/5772] 0.121662\n","[2/50] [600/5772] 0.028528\n","[2/50] [700/5772] 0.080763\n","[2/50] [800/5772] 0.105926\n","[2/50] [900/5772] 0.036895\n","[2/50] [1000/5772] 0.034231\n","[2/50] [1100/5772] 0.078428\n","[2/50] [1200/5772] 0.029447\n","[2/50] [1300/5772] 0.027037\n","[2/50] [1400/5772] 0.016031\n","[2/50] [1500/5772] 0.064721\n","[2/50] [1600/5772] 0.081879\n","[2/50] [1700/5772] 0.081467\n","[2/50] [1800/5772] 0.135337\n","[2/50] [1900/5772] 0.034207\n","[2/50] [2000/5772] 0.044568\n","[2/50] [2100/5772] 0.068475\n","[2/50] [2200/5772] 0.026458\n","[2/50] [2300/5772] 0.076097\n","[2/50] [2400/5772] 0.046471\n","[2/50] [2500/5772] 0.072169\n","[2/50] [2600/5772] 0.057945\n","[2/50] [2700/5772] 0.033633\n","[2/50] [2800/5772] 0.085403\n","[2/50] [2900/5772] 0.104321\n","[2/50] [3000/5772] 0.054396\n","[2/50] [3100/5772] 0.110341\n","[2/50] [3200/5772] 0.080264\n","[2/50] [3300/5772] 0.045561\n","[2/50] [3400/5772] 0.082101\n","[2/50] [3500/5772] 0.055507\n","[2/50] [3600/5772] 0.066593\n","[2/50] [3700/5772] 0.058974\n","[2/50] [3800/5772] 0.065603\n","[2/50] [3900/5772] 0.031581\n","[2/50] [4000/5772] 0.062685\n","[2/50] [4100/5772] 0.087004\n","[2/50] [4200/5772] 0.040528\n","[2/50] [4300/5772] 0.104765\n","[2/50] [4400/5772] 0.019723\n","[2/50] [4500/5772] 0.222326\n","[2/50] [4600/5772] 0.122573\n","[2/50] [4700/5772] 0.044439\n","[2/50] [4800/5772] 0.082861\n","[2/50] [4900/5772] 0.046858\n","[2/50] [5000/5772] 0.070927\n","[2/50] [5100/5772] 0.041378\n","[2/50] [5200/5772] 0.052992\n","[2/50] [5300/5772] 0.178764\n","[2/50] [5400/5772] 0.015613\n","[2/50] [5500/5772] 0.029924\n","[2/50] [5600/5772] 0.181048\n","[2/50] [5700/5772] 0.021474\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 635/635 [03:32<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'joint_goal_accuracy': 0.467192118226601, 'turn_slot_accuracy': 0.9801072796934951, 'turn_slot_f1': 0.9100871635878389}\n","joint_goal_accuracy: 0.467192118226601\n","turn_slot_accuracy: 0.9801072796934951\n","turn_slot_f1: 0.9100871635878389\n","[3/50] [0/5772] 0.159405\n","[3/50] [100/5772] 0.030887\n","[3/50] [200/5772] 0.025884\n","[3/50] [300/5772] 0.019922\n","[3/50] [400/5772] 0.144278\n","[3/50] [500/5772] 0.072006\n","[3/50] [600/5772] 0.102847\n","[3/50] [700/5772] 0.049376\n","[3/50] [800/5772] 0.032671\n","[3/50] [900/5772] 0.087325\n","[3/50] [1000/5772] 0.021264\n","[3/50] [1100/5772] 0.045128\n","[3/50] [1200/5772] 0.022619\n","[3/50] [1300/5772] 0.059963\n","[3/50] [1400/5772] 0.059034\n","[3/50] [1500/5772] 0.116153\n","[3/50] [1600/5772] 0.045907\n","[3/50] [1700/5772] 0.034479\n","[3/50] [1800/5772] 0.028078\n","[3/50] [1900/5772] 0.051269\n","[3/50] [2000/5772] 0.039380\n","[3/50] [2100/5772] 0.132835\n","[3/50] [2200/5772] 0.017018\n","[3/50] [2300/5772] 0.046540\n","[3/50] [2400/5772] 0.029602\n","[3/50] [2500/5772] 0.032577\n","[3/50] [2600/5772] 0.038317\n","[3/50] [2700/5772] 0.039199\n","[3/50] [2800/5772] 0.024552\n","[3/50] [2900/5772] 0.022592\n","[3/50] [3000/5772] 0.036698\n","[3/50] [3100/5772] 0.037000\n","[3/50] [3200/5772] 0.019509\n","[3/50] [3300/5772] 0.032037\n","[3/50] [3400/5772] 0.052498\n","[3/50] [3500/5772] 0.029808\n","[3/50] [3600/5772] 0.019079\n","[3/50] [3700/5772] 0.139194\n","[3/50] [3800/5772] 0.026498\n","[3/50] [3900/5772] 0.096560\n","[3/50] [4000/5772] 0.020667\n","[3/50] [4100/5772] 0.066239\n","[3/50] [4200/5772] 0.021572\n","[3/50] [4300/5772] 0.043457\n","[3/50] [4400/5772] 0.030716\n","[3/50] [4500/5772] 0.039909\n","[3/50] [4600/5772] 0.017160\n","[3/50] [4700/5772] 0.033825\n","[3/50] [4800/5772] 0.013557\n","[3/50] [4900/5772] 0.033614\n","[3/50] [5000/5772] 0.015514\n","[3/50] [5100/5772] 0.052887\n","[3/50] [5200/5772] 0.068600\n","[3/50] [5300/5772] 0.078988\n","[3/50] [5400/5772] 0.069144\n","[3/50] [5500/5772] 0.011198\n","[3/50] [5600/5772] 0.035084\n","[3/50] [5700/5772] 0.293522\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 635/635 [03:32<00:00,  2.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["{'joint_goal_accuracy': 0.4845320197044335, 'turn_slot_accuracy': 0.9816179529283082, 'turn_slot_f1': 0.9171370625201847}\n","joint_goal_accuracy: 0.4845320197044335\n","turn_slot_accuracy: 0.9816179529283082\n","turn_slot_f1: 0.9171370625201847\n","[4/50] [0/5772] 0.012152\n","[4/50] [100/5772] 0.014108\n","[4/50] [200/5772] 0.015004\n","[4/50] [300/5772] 0.018516\n","[4/50] [400/5772] 0.049016\n","[4/50] [500/5772] 0.042942\n","[4/50] [600/5772] 0.008636\n","[4/50] [700/5772] 0.024726\n","[4/50] [800/5772] 0.034927\n","[4/50] [900/5772] 0.034680\n","[4/50] [1000/5772] 0.076988\n","[4/50] [1100/5772] 0.036638\n","[4/50] [1200/5772] 0.035157\n","[4/50] [1300/5772] 0.048419\n","[4/50] [1400/5772] 0.057011\n","[4/50] [1500/5772] 0.024379\n","[4/50] [1600/5772] 0.013077\n","[4/50] [1700/5772] 0.035915\n","[4/50] [1800/5772] 0.023194\n","[4/50] [1900/5772] 0.016011\n","[4/50] [2000/5772] 0.025617\n","[4/50] [2100/5772] 0.065243\n","[4/50] [2200/5772] 0.045565\n","[4/50] [2300/5772] 0.012438\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-bb4e5a998069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"UR4EEzbz04XK"},"source":["## Inference "]},{"cell_type":"code","metadata":{"id":"jOJqYcpP04XK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621501197357,"user_tz":-540,"elapsed":115641,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"dd7d536a-9473-4a37-decd-f391d6297976"},"source":["eval_data = json.load(open(f\"/content/drive/MyDrive/Stage3/input/data/eval_dataset/eval_dials.json\", \"r\"))\n","\n","eval_examples = get_examples_from_dialogues(\n","    eval_data, user_first=False, dialogue_level=False\n",")\n","\n","# Extracting Featrues\n","eval_features = processor.convert_examples_to_features(eval_examples)\n","eval_data = WOSDataset(eval_features)\n","eval_sampler = SequentialSampler(eval_data)\n","eval_loader = DataLoader(\n","    eval_data,\n","    batch_size=8,\n","    sampler=eval_sampler,\n","    collate_fn=processor.collate_fn,\n",")"],"execution_count":16,"outputs":[{"output_type":"stream","text":["100%|██████████| 2000/2000 [00:00<00:00, 12765.23it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"nLU16_Ur04XL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621501792762,"user_tz":-540,"elapsed":695503,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}},"outputId":"45423d5a-caf7-402c-9380-727326b25d1a"},"source":["model.load_state_dict(torch.load(\"/content/drive/MyDrive/Stage3/model/Trade_segment_transformer_best.pt\"))\n","model= model.eval()\n","predictions = inference(model, eval_loader, processor, device)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["100%|██████████| 1847/1847 [09:50<00:00,  3.13it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"a0uR9J8e04XL","executionInfo":{"status":"ok","timestamp":1621502023625,"user_tz":-540,"elapsed":1036,"user":{"displayName":"오세민","photoUrl":"","userId":"15789962604001692355"}}},"source":["json.dump(predictions, open('/content/drive/MyDrive/Stage3/Trade_segment_transformer.csv', 'w'), indent=2, ensure_ascii=False) "],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emYBw5przVDX"},"source":["## prediction alalysis"]},{"cell_type":"code","metadata":{"id":"rlSL1QSRzVDY"},"source":["model.load_state_dict(torch.load(\"/opt/ml/model/Trade50_best.pt\"))\n","model = model.eval()\n","predictions = inference(model, dev_loader, processor, device)\n","eval_result = _evaluation(predictions, dev_labels, slot_meta)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UdLbb4FAzVDZ"},"source":["cat_ontology = []\n","noncat_ontology = []\n","for i in range(45):\n","    if len(list(ontology.items())[i][1]) <=9:\n","        cat_ontology.append(list(ontology.items())[i][0])\n","    else:\n","        noncat_ontology.append(list(ontology.items())[i][0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KoOid1qkzVDb"},"source":["category_pred = []\n","noncategory_pred = []\n","category_label = []\n","noncategory_label = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s9A25zhqzVDb"},"source":["pred_keys = list(predictions.keys())\n","pred_values = list(predictions.values())\n","labels_keys = list(dev_labels.keys())\n","labels_values = list(dev_labels.values())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2xqOaEezVDc"},"source":["correct = []\n","wrong = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WM4y3WmwzVDc"},"source":["# 전체 예측에 대해\n","last_key = ''\n","for num_labels in range(len(list(predictions))):\n","    \n","    # 마지막 예측이랑 비교해 새로운 예측만 생각\n","    if labels_keys[num_labels].split(':')[0] != last_key:\n","        last_pred = set([])\n","        last_label = set([])\n","        last_key = labels_keys[num_labels].split(':')[0]\n","    \n","    else:\n","        last_pred = set(pred_values[num_labels-1]) \n","        last_label = set(labels_values[num_labels-1])\n","    \n","    pred_slots = list(set(pred_values[num_labels]) - last_pred)\n","    label_slots = list(set(labels_values[num_labels]) - last_label)\n","                       \n","    #예측 안에 각각의 예측 slot에 대해\n","    for label_slot_num in range(len(label_slots)):\n","        \n","        # 정답에 예측이 있으면\n","        if label_slots[label_slot_num] in pred_slots:\n","            correct.append(label_slots[label_slot_num])\n","        else:\n","            wrong.append(label_slots[label_slot_num])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNMHBhOjzVDd"},"source":["print('len_correct:',len(correct))\n","print('len_wrong:',len(wrong))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9tZOf3ixzVDe"},"source":["cat_correct = []\n","noncat_correct = []\n","cat_wrong = []\n","noncat_wrong = []\n","for label in correct:\n","    if label.split('-')[0] + '-' +label.split('-')[1] in cat_ontology:\n","        cat_correct.append(label)\n","    else:\n","        noncat_correct.append(label)\n","for label in wrong:\n","    if label.split('-')[0] + '-' +label.split('-')[1] in cat_ontology:\n","        cat_wrong.append(label)\n","    else:\n","        noncat_wrong.append(label)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDiMASytzVDe"},"source":["print('cat_correct:',len(cat_correct))\n","print('noncat_correct:',len(noncat_correct))\n","print('cat_wrong:',len(cat_wrong))\n","print('noncat_wrong:',len(noncat_wrong))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7Dn3Fd3zVDf"},"source":["from collections import defaultdict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-jwnI3fzVDi"},"source":["cat_correct_dict = defaultdict(int)\n","noncat_correct_dict = defaultdict(int)\n","cat_wrong_dict = defaultdict(int)\n","noncat_wrong_dict = defaultdict(int)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e_qMfW_UzVDi"},"source":["for cat in cat_correct:\n","    cat_correct_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1\n","for cat in noncat_correct:\n","    noncat_correct_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1    \n","for cat in cat_wrong:\n","    cat_wrong_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1\n","for cat in noncat_wrong:\n","    noncat_wrong_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZCBs0hHzVDk"},"source":["print('cat 정답률')\n","for cat in cat_ontology:\n","    percent = cat_correct_dict[cat]/(cat_correct_dict[cat] + cat_wrong_dict[cat])*100\n","    print( str(cat), format(percent,\".2f\"),'%', '('+str(cat_correct_dict[cat])+'/'+str(cat_correct_dict[cat] + cat_wrong_dict[cat])+')')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQX7QO5ozVDk"},"source":["print('cat 오답률')\n","for cat in cat_ontology:\n","    percent = cat_wrong_dict[cat]/(cat_correct_dict[cat] + cat_wrong_dict[cat])*100\n","    print( str(cat), format(percent,\".2f\"),'%', '('+str(cat_wrong_dict[cat])+'/'+str(cat_correct_dict[cat] + cat_wrong_dict[cat])+')')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"16ugbJ2DzVDl"},"source":["print('noncat 정답률')\n","for cat in noncat_ontology:\n","    if noncat_correct_dict[cat] ==0:\n","        print(str(cat),' 0.00 %')\n","    else:\n","        percent = noncat_correct_dict[cat]/(noncat_correct_dict[cat] + noncat_wrong_dict[cat])*100\n","        print( str(cat), format(percent,\".2f\"),'%', '('+str(noncat_correct_dict[cat])+'/'+str(noncat_correct_dict[cat] + noncat_wrong_dict[cat])+')')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMPAo-bRzVDm"},"source":["print('noncat 오답률')\n","\n","for cat in noncat_ontology:\n","    if noncat_correct_dict[cat] ==0:\n","        print(str(cat),' 0.00 %')\n","    else:\n","        percent = noncat_wrong_dict[cat]/(noncat_correct_dict[cat] + noncat_wrong_dict[cat])*100\n","        print( str(cat), format(percent,\".2f\"),'%', '('+str(noncat_wrong_dict[cat])+'/'+str(noncat_correct_dict[cat] + noncat_wrong_dict[cat])+')')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJHxkMl1zVDn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_G0kpEglzVDo"},"source":[""],"execution_count":null,"outputs":[]}]}