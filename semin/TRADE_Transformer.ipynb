{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "TRADE_Transformer.ipynb",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUBti5G41WV0",
    "outputId": "51784783-7953-43ec-b1de-afd1898690d6"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eTBNo6R-1WSv"
   },
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Stage3/code')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JbCx8zyW1ZoN",
    "outputId": "b9566f49-0869-4ce9-f7ee-b1dff69b3582"
   },
   "source": [
    "!pip install transformers"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ITO1erJr04W8",
    "tags": []
   },
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "from data_utils import (\n",
    "    load_dataset, \n",
    "    get_examples_from_dialogues, \n",
    "    convert_state_dict, \n",
    "    DSTInputExample, \n",
    "    OpenVocabDSTFeature, \n",
    "    DSTPreprocessor, \n",
    "    WOSDataset)\n",
    "    \n",
    "from inference import inference\n",
    "from evaluation import _evaluation\n",
    "from data_utils import set_seed"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1Tw9bZT04XC"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-vdfArIOzVCy"
   },
   "source": [
    "set_seed(42)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O-6Xn5G504XD",
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9529ae01-b728-4a22-dc1b-7f9c61a564f3"
   },
   "source": [
    "train_data_file = \"/content/drive/MyDrive/Stage3/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/content/drive/MyDrive/Stage3/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/content/drive/MyDrive/Stage3/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "train_examples = get_examples_from_dialogues(train_data,\n",
    "                                             user_first=False,\n",
    "                                             dialogue_level=False)\n",
    "dev_examples = get_examples_from_dialogues(dev_data,\n",
    "                                           user_first=False,\n",
    "                                           dialogue_level=False)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 7063.13it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 12566.14it/s]\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6C9sqEXz04XE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6e45058d-aa13-4dd8-dd32-ce6ffec0b9be"
   },
   "source": [
    "print(len(train_examples))\n",
    "print(len(dev_examples))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hk2bVKMH04XE"
   },
   "source": [
    "## TRADE Preprocessor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaR5NuDp04XE"
   },
   "source": [
    "기존의 GRU 기반의 인코더를 BERT-based Encoder로 바꿀 준비를 합시다.\n",
    "\n",
    "1. 현재 `_convert_example_to_feature`에서는 `max_seq_length`를 핸들하고 있지 않습니다. `input_id`와 `segment_id`가 `max_seq_length`를 넘어가면 좌측부터 truncate시키는 코드를 삽입하세요.\n",
    "\n",
    "2. hybrid approach에서 얻은 교훈을 바탕으로 gate class를 3개에서 5개로 늘려봅시다.\n",
    "    - `gating2id`를 수정하세요\n",
    "    - 이에 따른 `recover_state`를 수정하세요.\n",
    "    \n",
    "3. word dropout을 구현하세요."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bo89P9d304XF",
    "tags": []
   },
   "source": [
    "class TRADEPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=512,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology\n",
    "        self.gating2id = {\"none\": 0, \"dontcare\": 1, \"yes\": 2, \"no\": 3, \"ptr\": 4}\n",
    "        self.id2gating = {v: k for k, v in self.gating2id.items()}\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n",
    "\n",
    "        input_id = self.src_tokenizer.encode(dialogue_context, add_special_tokens=False)\n",
    "        max_length = self.max_seq_length - 2\n",
    "        if len(input_id) > max_length:\n",
    "            gap = len(input_id) - max_length\n",
    "            input_id = input_id[gap:]\n",
    "\n",
    "        input_id = (\n",
    "            [self.src_tokenizer.cls_token_id]\n",
    "            + input_id\n",
    "            + [self.src_tokenizer.sep_token_id]\n",
    "        )\n",
    "        segment_id = [0] * len(input_id)\n",
    "\n",
    "        target_ids = []\n",
    "        gating_id = []\n",
    "        if not example.label:\n",
    "            example.label = []\n",
    "\n",
    "        state = convert_state_dict(example.label)\n",
    "        for slot in self.slot_meta:\n",
    "            value = state.get(slot, \"none\")\n",
    "            target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n",
    "                self.trg_tokenizer.sep_token_id\n",
    "            ]\n",
    "            target_ids.append(target_id)\n",
    "            gating_id.append(self.gating2id.get(value, self.gating2id[\"ptr\"]))\n",
    "        target_ids = self.pad_ids(target_ids, self.trg_tokenizer.pad_token_id)\n",
    "        return OpenVocabDSTFeature(\n",
    "            example.guid, input_id, segment_id, gating_id, target_ids\n",
    "        )\n",
    "\n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, gate_list, gen_list):\n",
    "        assert len(gate_list) == len(self.slot_meta)\n",
    "        assert len(gen_list) == len(self.slot_meta)\n",
    "\n",
    "        recovered = []\n",
    "        for slot, gate, value in zip(self.slot_meta, gate_list, gen_list):\n",
    "            if self.id2gating[gate] == \"none\":\n",
    "                continue\n",
    "\n",
    "            if self.id2gating[gate] in [\"dontcare\", \"yes\", \"no\"]:\n",
    "                recovered.append(\"%s-%s\" % (slot, self.id2gating[gate]))\n",
    "                continue\n",
    "\n",
    "            token_id_list = []\n",
    "            for id_ in value:\n",
    "                if id_ in self.trg_tokenizer.all_special_ids:\n",
    "                    break\n",
    "\n",
    "                token_id_list.append(id_)\n",
    "            value = self.trg_tokenizer.decode(token_id_list, skip_special_tokens=True)\n",
    "\n",
    "            if value == \"none\":\n",
    "                continue\n",
    "\n",
    "            recovered.append(\"%s-%s\" % (slot, value))\n",
    "        return recovered\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.input_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        segment_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.segment_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "\n",
    "        gating_ids = torch.LongTensor([b.gating_id for b in batch])\n",
    "        target_ids = self.pad_id_of_matrix(\n",
    "            [torch.LongTensor(b.target_ids) for b in batch],\n",
    "            self.trg_tokenizer.pad_token_id,\n",
    "        )\n",
    "        return input_ids, segment_ids, input_masks, gating_ids, target_ids, guids"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wd47XExT04XF"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zOjho3J404XG",
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5e2e2957-3b9f-48eb-d7d9-c3e36aed20fc"
   },
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)\n",
    "\n",
    "train_features = processor.convert_examples_to_features(train_examples)\n",
    "dev_features = processor.convert_examples_to_features(dev_examples)"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DFNdbCsB04XG",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3c09b175-7c86-4a13-dcd5-19a2e0a4e776"
   },
   "source": [
    "print(len(train_features))\n",
    "print(len(dev_features))"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "46170\n",
      "5075\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovQOZ9Sz04XH"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaivCGee04XH"
   },
   "source": [
    "1. `GRUEncoder`를 `BertModel`로 교체하세요. 이에 따라 `tie_weight` 함수가 수정되어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A7M4oZ1w04XH",
    "tags": []
   },
   "source": [
    "class TRADE(nn.Module):\n",
    "    def __init__(self, config, slot_vocab, slot_meta, pad_idx=0):\n",
    "        super(TRADE, self).__init__()\n",
    "        self.slot_meta = slot_meta\n",
    "        if config.model_name_or_path:\n",
    "            self.encoder = BertModel.from_pretrained(config.model_name_or_path)\n",
    "        else:\n",
    "            self.encoder = BertModel(config)\n",
    "            \n",
    "        self.decoder = SlotGenerator(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            config.hidden_dropout_prob,\n",
    "            config.n_gate,\n",
    "            None,\n",
    "            pad_idx,\n",
    "        )\n",
    "        \n",
    "        # init for only subword embedding\n",
    "        self.decoder.set_slot_idx(slot_vocab)\n",
    "        self.tie_weight()\n",
    "\n",
    "    def tie_weight(self):\n",
    "        self.decoder.embed.weight = self.encoder.embeddings.word_embeddings.weight\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask=None, max_len=10, teacher=None):\n",
    "\n",
    "        encoder_outputs, pooled_output = self.encoder(input_ids=input_ids,return_dict = False)\n",
    "        all_point_outputs, all_gate_outputs = self.decoder(\n",
    "            input_ids,\n",
    "            encoder_outputs,\n",
    "            pooled_output.unsqueeze(0), \n",
    "            attention_mask, \n",
    "            max_len, \n",
    "            teacher\n",
    "        )\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs\n",
    "    \n",
    "class SlotGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n",
    "    ):\n",
    "        super(SlotGenerator, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "        # 전체 보캡에 대해\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "\n",
    "        self.embed = nn.Embedding(\n",
    "            vocab_size, hidden_size, padding_idx=pad_idx\n",
    "        )  # shared with encoder\n",
    "\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "        self.hidden_size = proj_dim if proj_dim else hidden_size\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.gru = nn.GRU(\n",
    "        #    self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n",
    "        #)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=self.hidden_size, nhead=4)\n",
    "        self.transformer = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "\n",
    "        self.n_gate = n_gate\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_gen = nn.Linear(self.hidden_size * 3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n",
    "\n",
    "    def set_slot_idx(self, slot_vocab_idx):\n",
    "        whole = []\n",
    "        \n",
    "        #slot_vocab_idx 중 가장 긴거\n",
    "        max_length = max(map(len, slot_vocab_idx))\n",
    "        for idx in slot_vocab_idx:\n",
    "            if len(idx) < max_length:\n",
    "                gap = max_length - len(idx)\n",
    "                idx.extend([self.pad_idx] * gap)\n",
    "            whole.append(idx)\n",
    "            \n",
    "        #결국 whole == sumbt에서 slotlookup\n",
    "        self.slot_embed_idx = whole  # torch.LongTensor(whole)\n",
    "\n",
    "    def embedding(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n",
    "    ):\n",
    "        input_masks = input_masks.ne(1)\n",
    "        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n",
    "        # J,2\n",
    "        batch_size = encoder_output.size(0)\n",
    "        \n",
    "        slot = torch.LongTensor(self.slot_embed_idx).to(input_ids.device)  ## J, N, d\n",
    "        slot_e = torch.sum(self.embedding(slot), 1)  # J,d\n",
    "        \n",
    "        J = slot_e.size(0)\n",
    "\n",
    "        all_point_outputs = torch.zeros(batch_size, J, max_len, self.vocab_size).to(\n",
    "            input_ids.device\n",
    "        )\n",
    "        \n",
    "        # Parallel Decoding\n",
    "        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n",
    "        hidden = hidden.repeat_interleave(J, dim=1)\n",
    "        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n",
    "        input_ids = input_ids.repeat_interleave(J, dim=0)\n",
    "        input_masks = input_masks.repeat_interleave(J, dim=0)\n",
    "        \n",
    "        \n",
    "        for k in range(max_len):\n",
    "            w = self.dropout(w)\n",
    "            #_, hidden = self.gru(w, hidden)  # 1,B,D\n",
    "            hidden = self.transformer(hidden,w)\n",
    "\n",
    "            # B,T,D * B,D,1 => B,T\n",
    "            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n",
    "            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e9)\n",
    "            attn_history = F.softmax(attn_e, -1)  # B,T\n",
    "\n",
    "            if self.proj_layer:\n",
    "                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n",
    "            else:\n",
    "                hidden_proj = hidden\n",
    "\n",
    "            # B,D * D,V => B,V\n",
    "            attn_v = torch.matmul(\n",
    "                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n",
    "            )  # B,V\n",
    "            attn_vocab = F.softmax(attn_v, -1)\n",
    "\n",
    "            # B,1,T * B,T,D => B,1,D\n",
    "            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n",
    "            p_gen = self.sigmoid(\n",
    "                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n",
    "            )  # B,1\n",
    "            p_gen = p_gen.squeeze(-1)\n",
    "\n",
    "            p_context_ptr = torch.zeros_like(attn_vocab).to(input_ids.device)\n",
    "            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n",
    "            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n",
    "            _, w_idx = p_final.max(-1)\n",
    "\n",
    "            if teacher is not None:\n",
    "                w = self.embedding(teacher[:, :, k]).transpose(0, 1).reshape(batch_size * J, 1, -1)\n",
    "            else:\n",
    "                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n",
    "            if k == 0:\n",
    "                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n",
    "                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n",
    "            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdLS3jkA04XI"
   },
   "source": [
    "# 모델 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-MYTPvu004XI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "94cc10e8-c763-4129-b49b-67dd91f14372"
   },
   "source": [
    "slot_vocab = []\n",
    "for slot in slot_meta:\n",
    "    slot_vocab.append(\n",
    "        tokenizer.encode(slot.replace('-', ' '),\n",
    "                         add_special_tokens=False)\n",
    "    )\n",
    "    \n",
    "config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "config.n_gate = len(processor.gating2id)\n",
    "config.proj_dim = None\n",
    "model = TRADE(config, slot_vocab, slot_meta)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dsksd/bert-ko-small-minimal were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ksvFxR-h04XI",
    "tags": []
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=8, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVYxBaXE04XJ"
   },
   "source": [
    "# Optimizer & Scheduler 선언"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NmDmrigU04XJ",
    "tags": []
   },
   "source": [
    "n_epochs = 50\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0.1, num_training_steps=t_total\n",
    ")\n",
    "teacher_forcing = 0.5\n",
    "model.to(device)\n",
    "\n",
    "def masked_cross_entropy_for_value(logits, target, pad_idx=0):\n",
    "    mask = target.ne(pad_idx)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    log_probs_flat = torch.log(logits_flat)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / (mask.sum().float())\n",
    "    return loss\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()  # gating"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0GK3Z8z04XJ"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mrWnCWwC04XJ",
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fef7d3c3-90fa-4a7b-8eb1-70d9042e584b"
   },
   "source": [
    "best_score = 0\n",
    "cnt = 0\n",
    "for epoch in range(50):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, guids = [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        if teacher_forcing > 0.0 and random.random() < teacher_forcing:\n",
    "            tf = target_ids\n",
    "        else:\n",
    "            tf = None\n",
    "\n",
    "        all_point_outputs, all_gate_outputs = model(input_ids, segment_ids, input_masks, target_ids.size(-1))  # gt - length (generation)\n",
    "        loss_1 = loss_fnc_1(all_point_outputs.contiguous(), target_ids.contiguous().view(-1))\n",
    "        loss_2 = loss_fnc_2(all_gate_outputs.contiguous().view(-1, 5), gating_ids.contiguous().view(-1))\n",
    "        loss = loss_1 + loss_2\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:\n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n",
    "       \n",
    "    predictions = inference(model, dev_loader, processor, device)\n",
    "    eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "    score = eval_result['joint_goal_accuracy']\n",
    "    if score > best_score:\n",
    "        cnt = 0\n",
    "        best_score = score\n",
    "        torch.save(model.state_dict(), \"/content/drive/MyDrive/Stage3/model/trade_transformer_best.pt\")\n",
    "    \n",
    "    #else:\n",
    "    #    cnt += 1\n",
    "    #    if cnt == 5:\n",
    "    #        print('Early stop! Epoch:',str(epoch))\n",
    "    #        break\n",
    "    \n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/Stage3/model/trade_transformer_50.pt\")"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[0/50] [0/5772] 14.580219\n",
      "[0/50] [100/5772] 1.799422\n",
      "[0/50] [200/5772] 1.313414\n",
      "[0/50] [300/5772] 1.097592\n",
      "[0/50] [400/5772] 1.164865\n",
      "[0/50] [500/5772] 1.110765\n",
      "[0/50] [600/5772] 0.982610\n",
      "[0/50] [700/5772] 0.619534\n",
      "[0/50] [800/5772] 1.029133\n",
      "[0/50] [900/5772] 0.720882\n",
      "[0/50] [1000/5772] 0.660420\n",
      "[0/50] [1100/5772] 0.801211\n",
      "[0/50] [1200/5772] 0.356341\n",
      "[0/50] [1300/5772] 0.537013\n",
      "[0/50] [1400/5772] 0.421024\n",
      "[0/50] [1500/5772] 0.329704\n",
      "[0/50] [1600/5772] 0.410508\n",
      "[0/50] [1700/5772] 0.324571\n",
      "[0/50] [1800/5772] 0.279642\n",
      "[0/50] [1900/5772] 0.494037\n",
      "[0/50] [2000/5772] 0.482853\n",
      "[0/50] [2100/5772] 0.387975\n",
      "[0/50] [2200/5772] 0.189444\n",
      "[0/50] [2300/5772] 0.286721\n",
      "[0/50] [2400/5772] 0.491856\n",
      "[0/50] [2500/5772] 0.211968\n",
      "[0/50] [2600/5772] 0.324601\n",
      "[0/50] [2700/5772] 0.290303\n",
      "[0/50] [2800/5772] 0.265635\n",
      "[0/50] [2900/5772] 0.407552\n",
      "[0/50] [3000/5772] 0.324845\n",
      "[0/50] [3100/5772] 0.163235\n",
      "[0/50] [3200/5772] 0.251227\n",
      "[0/50] [3300/5772] 0.435465\n",
      "[0/50] [3400/5772] 0.238665\n",
      "[0/50] [3500/5772] 0.305190\n",
      "[0/50] [3600/5772] 0.258386\n",
      "[0/50] [3700/5772] 0.149477\n",
      "[0/50] [3800/5772] 0.250341\n",
      "[0/50] [3900/5772] 0.155416\n",
      "[0/50] [4000/5772] 0.241613\n",
      "[0/50] [4100/5772] 0.299727\n",
      "[0/50] [4200/5772] 0.275449\n",
      "[0/50] [4300/5772] 0.215321\n",
      "[0/50] [4400/5772] 0.175234\n",
      "[0/50] [4500/5772] 0.217833\n",
      "[0/50] [4600/5772] 0.179106\n",
      "[0/50] [4700/5772] 0.207084\n",
      "[0/50] [4800/5772] 0.364784\n",
      "[0/50] [4900/5772] 0.234378\n",
      "[0/50] [5000/5772] 0.199780\n",
      "[0/50] [5100/5772] 0.303219\n",
      "[0/50] [5200/5772] 0.366616\n",
      "[0/50] [5300/5772] 0.088006\n",
      "[0/50] [5400/5772] 0.196669\n",
      "[0/50] [5500/5772] 0.174999\n",
      "[0/50] [5600/5772] 0.244231\n",
      "[0/50] [5700/5772] 0.198940\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:24<00:00,  3.11it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.26817733990147785, 'turn_slot_accuracy': 0.9609808429118897, 'turn_slot_f1': 0.8305564428750309}\n",
      "joint_goal_accuracy: 0.26817733990147785\n",
      "turn_slot_accuracy: 0.9609808429118897\n",
      "turn_slot_f1: 0.8305564428750309\n",
      "[1/50] [0/5772] 0.074807\n",
      "[1/50] [100/5772] 0.072992\n",
      "[1/50] [200/5772] 0.263765\n",
      "[1/50] [300/5772] 0.194199\n",
      "[1/50] [400/5772] 0.146835\n",
      "[1/50] [500/5772] 0.145715\n",
      "[1/50] [600/5772] 0.204847\n",
      "[1/50] [700/5772] 0.155511\n",
      "[1/50] [800/5772] 0.141294\n",
      "[1/50] [900/5772] 0.146580\n",
      "[1/50] [1000/5772] 0.055936\n",
      "[1/50] [1100/5772] 0.335887\n",
      "[1/50] [1200/5772] 0.258134\n",
      "[1/50] [1300/5772] 0.147124\n",
      "[1/50] [1400/5772] 0.159916\n",
      "[1/50] [1500/5772] 0.098001\n",
      "[1/50] [1600/5772] 0.065705\n",
      "[1/50] [1700/5772] 0.306983\n",
      "[1/50] [1800/5772] 0.159120\n",
      "[1/50] [1900/5772] 0.175491\n",
      "[1/50] [2000/5772] 0.084745\n",
      "[1/50] [2100/5772] 0.077552\n",
      "[1/50] [2200/5772] 0.074623\n",
      "[1/50] [2300/5772] 0.294245\n",
      "[1/50] [2400/5772] 0.184570\n",
      "[1/50] [2500/5772] 0.063874\n",
      "[1/50] [2600/5772] 0.214664\n",
      "[1/50] [2700/5772] 0.097200\n",
      "[1/50] [2800/5772] 0.172535\n",
      "[1/50] [2900/5772] 0.047233\n",
      "[1/50] [3000/5772] 0.046122\n",
      "[1/50] [3100/5772] 0.145587\n",
      "[1/50] [3200/5772] 0.033491\n",
      "[1/50] [3300/5772] 0.097991\n",
      "[1/50] [3400/5772] 0.164599\n",
      "[1/50] [3500/5772] 0.053536\n",
      "[1/50] [3600/5772] 0.160575\n",
      "[1/50] [3700/5772] 0.063656\n",
      "[1/50] [3800/5772] 0.043724\n",
      "[1/50] [3900/5772] 0.055578\n",
      "[1/50] [4000/5772] 0.106470\n",
      "[1/50] [4100/5772] 0.120778\n",
      "[1/50] [4200/5772] 0.092986\n",
      "[1/50] [4300/5772] 0.090551\n",
      "[1/50] [4400/5772] 0.029551\n",
      "[1/50] [4500/5772] 0.070507\n",
      "[1/50] [4600/5772] 0.046922\n",
      "[1/50] [4700/5772] 0.057722\n",
      "[1/50] [4800/5772] 0.098966\n",
      "[1/50] [4900/5772] 0.086277\n",
      "[1/50] [5000/5772] 0.122776\n",
      "[1/50] [5100/5772] 0.036150\n",
      "[1/50] [5200/5772] 0.094070\n",
      "[1/50] [5300/5772] 0.106889\n",
      "[1/50] [5400/5772] 0.068612\n",
      "[1/50] [5500/5772] 0.048927\n",
      "[1/50] [5600/5772] 0.046972\n",
      "[1/50] [5700/5772] 0.158490\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:23<00:00,  3.12it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.43566502463054185, 'turn_slot_accuracy': 0.9773705528188388, 'turn_slot_f1': 0.9010856418506622}\n",
      "joint_goal_accuracy: 0.43566502463054185\n",
      "turn_slot_accuracy: 0.9773705528188388\n",
      "turn_slot_f1: 0.9010856418506622\n",
      "[2/50] [0/5772] 0.144767\n",
      "[2/50] [100/5772] 0.056230\n",
      "[2/50] [200/5772] 0.059657\n",
      "[2/50] [300/5772] 0.121703\n",
      "[2/50] [400/5772] 0.070102\n",
      "[2/50] [500/5772] 0.061185\n",
      "[2/50] [600/5772] 0.029831\n",
      "[2/50] [700/5772] 0.063854\n",
      "[2/50] [800/5772] 0.028859\n",
      "[2/50] [900/5772] 0.023527\n",
      "[2/50] [1000/5772] 0.063998\n",
      "[2/50] [1100/5772] 0.056254\n",
      "[2/50] [1200/5772] 0.035034\n",
      "[2/50] [1300/5772] 0.018169\n",
      "[2/50] [1400/5772] 0.014311\n",
      "[2/50] [1500/5772] 0.047408\n",
      "[2/50] [1600/5772] 0.065399\n",
      "[2/50] [1700/5772] 0.079548\n",
      "[2/50] [1800/5772] 0.146240\n",
      "[2/50] [1900/5772] 0.054216\n",
      "[2/50] [2000/5772] 0.051484\n",
      "[2/50] [2100/5772] 0.042907\n",
      "[2/50] [2200/5772] 0.027852\n",
      "[2/50] [2300/5772] 0.072107\n",
      "[2/50] [2400/5772] 0.072363\n",
      "[2/50] [2500/5772] 0.148040\n",
      "[2/50] [2600/5772] 0.084139\n",
      "[2/50] [2700/5772] 0.088724\n",
      "[2/50] [2800/5772] 0.106344\n",
      "[2/50] [2900/5772] 0.160562\n",
      "[2/50] [3000/5772] 0.032858\n",
      "[2/50] [3100/5772] 0.038935\n",
      "[2/50] [3200/5772] 0.062348\n",
      "[2/50] [3300/5772] 0.030067\n",
      "[2/50] [3400/5772] 0.067505\n",
      "[2/50] [3500/5772] 0.064929\n",
      "[2/50] [3600/5772] 0.104735\n",
      "[2/50] [3700/5772] 0.080118\n",
      "[2/50] [3800/5772] 0.049335\n",
      "[2/50] [3900/5772] 0.043288\n",
      "[2/50] [4000/5772] 0.093131\n",
      "[2/50] [4100/5772] 0.044175\n",
      "[2/50] [4200/5772] 0.031174\n",
      "[2/50] [4300/5772] 0.027014\n",
      "[2/50] [4400/5772] 0.031618\n",
      "[2/50] [4500/5772] 0.155442\n",
      "[2/50] [4600/5772] 0.079323\n",
      "[2/50] [4700/5772] 0.046651\n",
      "[2/50] [4800/5772] 0.060441\n",
      "[2/50] [4900/5772] 0.039857\n",
      "[2/50] [5000/5772] 0.056149\n",
      "[2/50] [5100/5772] 0.066505\n",
      "[2/50] [5200/5772] 0.051017\n",
      "[2/50] [5300/5772] 0.092230\n",
      "[2/50] [5400/5772] 0.016478\n",
      "[2/50] [5500/5772] 0.044686\n",
      "[2/50] [5600/5772] 0.112868\n",
      "[2/50] [5700/5772] 0.023915\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:24<00:00,  3.10it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.4697536945812808, 'turn_slot_accuracy': 0.9804137931034579, 'turn_slot_f1': 0.9115016577493336}\n",
      "joint_goal_accuracy: 0.4697536945812808\n",
      "turn_slot_accuracy: 0.9804137931034579\n",
      "turn_slot_f1: 0.9115016577493336\n",
      "[3/50] [0/5772] 0.142354\n",
      "[3/50] [100/5772] 0.034892\n",
      "[3/50] [200/5772] 0.033291\n",
      "[3/50] [300/5772] 0.019379\n",
      "[3/50] [400/5772] 0.126657\n",
      "[3/50] [500/5772] 0.032178\n",
      "[3/50] [600/5772] 0.038848\n",
      "[3/50] [700/5772] 0.059347\n",
      "[3/50] [800/5772] 0.051442\n",
      "[3/50] [900/5772] 0.029018\n",
      "[3/50] [1000/5772] 0.034792\n",
      "[3/50] [1100/5772] 0.050375\n",
      "[3/50] [1200/5772] 0.018115\n",
      "[3/50] [1300/5772] 0.036548\n",
      "[3/50] [1400/5772] 0.063504\n",
      "[3/50] [1500/5772] 0.097785\n",
      "[3/50] [1600/5772] 0.044996\n",
      "[3/50] [1700/5772] 0.041430\n",
      "[3/50] [1800/5772] 0.036977\n",
      "[3/50] [1900/5772] 0.092151\n",
      "[3/50] [2000/5772] 0.047847\n",
      "[3/50] [2100/5772] 0.109449\n",
      "[3/50] [2200/5772] 0.058441\n",
      "[3/50] [2300/5772] 0.087251\n",
      "[3/50] [2400/5772] 0.027813\n",
      "[3/50] [2500/5772] 0.058661\n",
      "[3/50] [2600/5772] 0.049449\n",
      "[3/50] [2700/5772] 0.038378\n",
      "[3/50] [2800/5772] 0.028871\n",
      "[3/50] [2900/5772] 0.017635\n",
      "[3/50] [3000/5772] 0.037693\n",
      "[3/50] [3100/5772] 0.071773\n",
      "[3/50] [3200/5772] 0.019313\n",
      "[3/50] [3300/5772] 0.030211\n",
      "[3/50] [3400/5772] 0.020708\n",
      "[3/50] [3500/5772] 0.030906\n",
      "[3/50] [3600/5772] 0.014462\n",
      "[3/50] [3700/5772] 0.065596\n",
      "[3/50] [3800/5772] 0.045758\n",
      "[3/50] [3900/5772] 0.049440\n",
      "[3/50] [4000/5772] 0.021245\n",
      "[3/50] [4100/5772] 0.034283\n",
      "[3/50] [4200/5772] 0.015519\n",
      "[3/50] [4300/5772] 0.023495\n",
      "[3/50] [4400/5772] 0.058401\n",
      "[3/50] [4500/5772] 0.065749\n",
      "[3/50] [4600/5772] 0.019255\n",
      "[3/50] [4700/5772] 0.032841\n",
      "[3/50] [4800/5772] 0.016362\n",
      "[3/50] [4900/5772] 0.010085\n",
      "[3/50] [5000/5772] 0.038204\n",
      "[3/50] [5100/5772] 0.073623\n",
      "[3/50] [5200/5772] 0.050146\n",
      "[3/50] [5300/5772] 0.028714\n",
      "[3/50] [5400/5772] 0.044763\n",
      "[3/50] [5500/5772] 0.011162\n",
      "[3/50] [5600/5772] 0.032926\n",
      "[3/50] [5700/5772] 0.291443\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:23<00:00,  3.12it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.4742857142857143, 'turn_slot_accuracy': 0.9811756978653611, 'turn_slot_f1': 0.9138630162578961}\n",
      "joint_goal_accuracy: 0.4742857142857143\n",
      "turn_slot_accuracy: 0.9811756978653611\n",
      "turn_slot_f1: 0.9138630162578961\n",
      "[4/50] [0/5772] 0.041936\n",
      "[4/50] [100/5772] 0.012851\n",
      "[4/50] [200/5772] 0.010555\n",
      "[4/50] [300/5772] 0.028024\n",
      "[4/50] [400/5772] 0.067514\n",
      "[4/50] [500/5772] 0.044524\n",
      "[4/50] [600/5772] 0.055532\n",
      "[4/50] [700/5772] 0.028846\n",
      "[4/50] [800/5772] 0.038270\n",
      "[4/50] [900/5772] 0.021914\n",
      "[4/50] [1000/5772] 0.074852\n",
      "[4/50] [1100/5772] 0.022508\n",
      "[4/50] [1200/5772] 0.068371\n",
      "[4/50] [1300/5772] 0.027170\n",
      "[4/50] [1400/5772] 0.053735\n",
      "[4/50] [1500/5772] 0.022471\n",
      "[4/50] [1600/5772] 0.014714\n",
      "[4/50] [1700/5772] 0.016580\n",
      "[4/50] [1800/5772] 0.023762\n",
      "[4/50] [1900/5772] 0.015684\n",
      "[4/50] [2000/5772] 0.023169\n",
      "[4/50] [2100/5772] 0.073873\n",
      "[4/50] [2200/5772] 0.046131\n",
      "[4/50] [2300/5772] 0.011392\n",
      "[4/50] [2400/5772] 0.015715\n",
      "[4/50] [2500/5772] 0.056515\n",
      "[4/50] [2600/5772] 0.061651\n",
      "[4/50] [2700/5772] 0.046786\n",
      "[4/50] [2800/5772] 0.025975\n",
      "[4/50] [2900/5772] 0.031677\n",
      "[4/50] [3000/5772] 0.060507\n",
      "[4/50] [3100/5772] 0.028722\n",
      "[4/50] [3200/5772] 0.022009\n",
      "[4/50] [3300/5772] 0.024109\n",
      "[4/50] [3400/5772] 0.010094\n",
      "[4/50] [3500/5772] 0.013041\n",
      "[4/50] [3600/5772] 0.098138\n",
      "[4/50] [3700/5772] 0.019171\n",
      "[4/50] [3800/5772] 0.058768\n",
      "[4/50] [3900/5772] 0.021937\n",
      "[4/50] [4000/5772] 0.019013\n",
      "[4/50] [4100/5772] 0.036107\n",
      "[4/50] [4200/5772] 0.024672\n",
      "[4/50] [4300/5772] 0.085996\n",
      "[4/50] [4400/5772] 0.021358\n",
      "[4/50] [4500/5772] 0.015496\n",
      "[4/50] [4600/5772] 0.002895\n",
      "[4/50] [4700/5772] 0.013969\n",
      "[4/50] [4800/5772] 0.082593\n",
      "[4/50] [4900/5772] 0.070845\n",
      "[4/50] [5000/5772] 0.111223\n",
      "[4/50] [5100/5772] 0.058077\n",
      "[4/50] [5200/5772] 0.052484\n",
      "[4/50] [5300/5772] 0.027441\n",
      "[4/50] [5400/5772] 0.108236\n",
      "[4/50] [5500/5772] 0.052463\n",
      "[4/50] [5600/5772] 0.029955\n",
      "[4/50] [5700/5772] 0.019170\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:22<00:00,  3.13it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.5288669950738917, 'turn_slot_accuracy': 0.9840350301040054, 'turn_slot_f1': 0.9263899212391653}\n",
      "joint_goal_accuracy: 0.5288669950738917\n",
      "turn_slot_accuracy: 0.9840350301040054\n",
      "turn_slot_f1: 0.9263899212391653\n",
      "[5/50] [0/5772] 0.057221\n",
      "[5/50] [100/5772] 0.031417\n",
      "[5/50] [200/5772] 0.039968\n",
      "[5/50] [300/5772] 0.035807\n",
      "[5/50] [400/5772] 0.033044\n",
      "[5/50] [500/5772] 0.102353\n",
      "[5/50] [600/5772] 0.061854\n",
      "[5/50] [700/5772] 0.046420\n",
      "[5/50] [800/5772] 0.004013\n",
      "[5/50] [900/5772] 0.016188\n",
      "[5/50] [1000/5772] 0.034503\n",
      "[5/50] [1100/5772] 0.072398\n",
      "[5/50] [1200/5772] 0.090374\n",
      "[5/50] [1300/5772] 0.013725\n",
      "[5/50] [1400/5772] 0.030171\n",
      "[5/50] [1500/5772] 0.013318\n",
      "[5/50] [1600/5772] 0.056119\n",
      "[5/50] [1700/5772] 0.027558\n",
      "[5/50] [1800/5772] 0.026843\n",
      "[5/50] [1900/5772] 0.015940\n",
      "[5/50] [2000/5772] 0.023092\n",
      "[5/50] [2100/5772] 0.068177\n",
      "[5/50] [2200/5772] 0.033729\n",
      "[5/50] [2300/5772] 0.022229\n",
      "[5/50] [2400/5772] 0.012882\n",
      "[5/50] [2500/5772] 0.066802\n",
      "[5/50] [2600/5772] 0.073328\n",
      "[5/50] [2700/5772] 0.037280\n",
      "[5/50] [2800/5772] 0.079671\n",
      "[5/50] [2900/5772] 0.069945\n",
      "[5/50] [3000/5772] 0.057235\n",
      "[5/50] [3100/5772] 0.036279\n",
      "[5/50] [3200/5772] 0.009553\n",
      "[5/50] [3300/5772] 0.022538\n",
      "[5/50] [3400/5772] 0.022559\n",
      "[5/50] [3500/5772] 0.008084\n",
      "[5/50] [3600/5772] 0.014705\n",
      "[5/50] [3700/5772] 0.026275\n",
      "[5/50] [3800/5772] 0.010317\n",
      "[5/50] [3900/5772] 0.061710\n",
      "[5/50] [4000/5772] 0.012167\n",
      "[5/50] [4100/5772] 0.049699\n",
      "[5/50] [4200/5772] 0.051688\n",
      "[5/50] [4300/5772] 0.026023\n",
      "[5/50] [4400/5772] 0.030990\n",
      "[5/50] [4500/5772] 0.038002\n",
      "[5/50] [4600/5772] 0.008306\n",
      "[5/50] [4700/5772] 0.015937\n",
      "[5/50] [4800/5772] 0.060688\n",
      "[5/50] [4900/5772] 0.032778\n",
      "[5/50] [5000/5772] 0.030132\n",
      "[5/50] [5100/5772] 0.018554\n",
      "[5/50] [5200/5772] 0.023362\n",
      "[5/50] [5300/5772] 0.030680\n",
      "[5/50] [5400/5772] 0.079999\n",
      "[5/50] [5500/5772] 0.028630\n",
      "[5/50] [5600/5772] 0.129156\n",
      "[5/50] [5700/5772] 0.021131\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:22<00:00,  3.13it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.572216748768473, 'turn_slot_accuracy': 0.9857120963327973, 'turn_slot_f1': 0.9355236713104385}\n",
      "joint_goal_accuracy: 0.572216748768473\n",
      "turn_slot_accuracy: 0.9857120963327973\n",
      "turn_slot_f1: 0.9355236713104385\n",
      "[6/50] [0/5772] 0.009183\n",
      "[6/50] [100/5772] 0.009917\n",
      "[6/50] [200/5772] 0.037646\n",
      "[6/50] [300/5772] 0.043110\n",
      "[6/50] [400/5772] 0.035132\n",
      "[6/50] [500/5772] 0.043881\n",
      "[6/50] [600/5772] 0.026550\n",
      "[6/50] [700/5772] 0.028173\n",
      "[6/50] [800/5772] 0.025168\n",
      "[6/50] [900/5772] 0.063303\n",
      "[6/50] [1000/5772] 0.032872\n",
      "[6/50] [1100/5772] 0.016185\n",
      "[6/50] [1200/5772] 0.029769\n",
      "[6/50] [1300/5772] 0.038741\n",
      "[6/50] [1400/5772] 0.066944\n",
      "[6/50] [1500/5772] 0.021678\n",
      "[6/50] [1600/5772] 0.044456\n",
      "[6/50] [1700/5772] 0.072068\n",
      "[6/50] [1800/5772] 0.022857\n",
      "[6/50] [1900/5772] 0.018557\n",
      "[6/50] [2000/5772] 0.009240\n",
      "[6/50] [2100/5772] 0.012642\n",
      "[6/50] [2200/5772] 0.003028\n",
      "[6/50] [2300/5772] 0.030944\n",
      "[6/50] [2400/5772] 0.016136\n",
      "[6/50] [2500/5772] 0.053249\n",
      "[6/50] [2600/5772] 0.013971\n",
      "[6/50] [2700/5772] 0.014781\n",
      "[6/50] [2800/5772] 0.016383\n",
      "[6/50] [2900/5772] 0.114057\n",
      "[6/50] [3000/5772] 0.008205\n",
      "[6/50] [3100/5772] 0.044671\n",
      "[6/50] [3200/5772] 0.048064\n",
      "[6/50] [3300/5772] 0.025842\n",
      "[6/50] [3400/5772] 0.056158\n",
      "[6/50] [3500/5772] 0.017443\n",
      "[6/50] [3600/5772] 0.066386\n",
      "[6/50] [3700/5772] 0.032129\n",
      "[6/50] [3800/5772] 0.028043\n",
      "[6/50] [3900/5772] 0.009220\n",
      "[6/50] [4000/5772] 0.013135\n",
      "[6/50] [4100/5772] 0.031819\n",
      "[6/50] [4200/5772] 0.007626\n",
      "[6/50] [4300/5772] 0.023953\n",
      "[6/50] [4400/5772] 0.010117\n",
      "[6/50] [4500/5772] 0.024633\n",
      "[6/50] [4600/5772] 0.019735\n",
      "[6/50] [4700/5772] 0.019243\n",
      "[6/50] [4800/5772] 0.023163\n",
      "[6/50] [4900/5772] 0.031738\n",
      "[6/50] [5000/5772] 0.015178\n",
      "[6/50] [5100/5772] 0.007895\n",
      "[6/50] [5200/5772] 0.036577\n",
      "[6/50] [5300/5772] 0.011284\n",
      "[6/50] [5400/5772] 0.028405\n",
      "[6/50] [5500/5772] 0.017329\n",
      "[6/50] [5600/5772] 0.089034\n",
      "[6/50] [5700/5772] 0.058468\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 635/635 [03:24<00:00,  3.11it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.601576354679803, 'turn_slot_accuracy': 0.9866622879036762, 'turn_slot_f1': 0.9410965339865369}\n",
      "joint_goal_accuracy: 0.601576354679803\n",
      "turn_slot_accuracy: 0.9866622879036762\n",
      "turn_slot_f1: 0.9410965339865369\n",
      "[7/50] [0/5772] 0.016057\n",
      "[7/50] [100/5772] 0.029807\n",
      "[7/50] [200/5772] 0.030734\n",
      "[7/50] [300/5772] 0.019526\n",
      "[7/50] [400/5772] 0.027479\n",
      "[7/50] [500/5772] 0.059003\n",
      "[7/50] [600/5772] 0.011991\n",
      "[7/50] [700/5772] 0.020414\n",
      "[7/50] [800/5772] 0.027785\n",
      "[7/50] [900/5772] 0.015690\n",
      "[7/50] [1000/5772] 0.024412\n",
      "[7/50] [1100/5772] 0.008233\n",
      "[7/50] [1200/5772] 0.046906\n",
      "[7/50] [1300/5772] 0.007725\n",
      "[7/50] [1400/5772] 0.018253\n",
      "[7/50] [1500/5772] 0.007185\n",
      "[7/50] [1600/5772] 0.030455\n",
      "[7/50] [1700/5772] 0.045907\n",
      "[7/50] [1800/5772] 0.032454\n",
      "[7/50] [1900/5772] 0.010267\n",
      "[7/50] [2000/5772] 0.043917\n",
      "[7/50] [2100/5772] 0.070668\n",
      "[7/50] [2200/5772] 0.060904\n",
      "[7/50] [2300/5772] 0.055462\n",
      "[7/50] [2400/5772] 0.016060\n",
      "[7/50] [2500/5772] 0.041352\n",
      "[7/50] [2600/5772] 0.011628\n",
      "[7/50] [2700/5772] 0.014606\n",
      "[7/50] [2800/5772] 0.020074\n",
      "[7/50] [2900/5772] 0.023624\n",
      "[7/50] [3000/5772] 0.034722\n",
      "[7/50] [3100/5772] 0.007597\n",
      "[7/50] [3200/5772] 0.045034\n",
      "[7/50] [3300/5772] 0.033835\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4EEzbz04XK"
   },
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jOJqYcpP04XK"
   },
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/input/data/eval_dataset/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nLU16_Ur04XL"
   },
   "source": [
    "model.load_state_dict(torch.load(\"/opt/ml/model/Trade50_best.pt\"))\n",
    "model= model.eval()\n",
    "predictions = inference(model, eval_loader, processor, device)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a0uR9J8e04XL"
   },
   "source": [
    "json.dump(predictions, open('predictions50_best.csv', 'w'), indent=2, ensure_ascii=False) "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emYBw5przVDX"
   },
   "source": [
    "## prediction alalysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rlSL1QSRzVDY"
   },
   "source": [
    "model.load_state_dict(torch.load(\"/opt/ml/model/Trade50_best.pt\"))\n",
    "model = model.eval()\n",
    "predictions = inference(model, dev_loader, processor, device)\n",
    "eval_result = _evaluation(predictions, dev_labels, slot_meta)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UdLbb4FAzVDZ"
   },
   "source": [
    "cat_ontology = []\n",
    "noncat_ontology = []\n",
    "for i in range(45):\n",
    "    if len(list(ontology.items())[i][1]) <=9:\n",
    "        cat_ontology.append(list(ontology.items())[i][0])\n",
    "    else:\n",
    "        noncat_ontology.append(list(ontology.items())[i][0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KoOid1qkzVDb"
   },
   "source": [
    "category_pred = []\n",
    "noncategory_pred = []\n",
    "category_label = []\n",
    "noncategory_label = []"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s9A25zhqzVDb"
   },
   "source": [
    "pred_keys = list(predictions.keys())\n",
    "pred_values = list(predictions.values())\n",
    "labels_keys = list(dev_labels.keys())\n",
    "labels_values = list(dev_labels.values())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C2xqOaEezVDc"
   },
   "source": [
    "correct = []\n",
    "wrong = []"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM4y3WmwzVDc"
   },
   "source": [
    "# 전체 예측에 대해\n",
    "last_key = ''\n",
    "for num_labels in range(len(list(predictions))):\n",
    "    \n",
    "    # 마지막 예측이랑 비교해 새로운 예측만 생각\n",
    "    if labels_keys[num_labels].split(':')[0] != last_key:\n",
    "        last_pred = set([])\n",
    "        last_label = set([])\n",
    "        last_key = labels_keys[num_labels].split(':')[0]\n",
    "    \n",
    "    else:\n",
    "        last_pred = set(pred_values[num_labels-1]) \n",
    "        last_label = set(labels_values[num_labels-1])\n",
    "    \n",
    "    pred_slots = list(set(pred_values[num_labels]) - last_pred)\n",
    "    label_slots = list(set(labels_values[num_labels]) - last_label)\n",
    "                       \n",
    "    #예측 안에 각각의 예측 slot에 대해\n",
    "    for label_slot_num in range(len(label_slots)):\n",
    "        \n",
    "        # 정답에 예측이 있으면\n",
    "        if label_slots[label_slot_num] in pred_slots:\n",
    "            correct.append(label_slots[label_slot_num])\n",
    "        else:\n",
    "            wrong.append(label_slots[label_slot_num])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TNMHBhOjzVDd"
   },
   "source": [
    "print('len_correct:',len(correct))\n",
    "print('len_wrong:',len(wrong))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9tZOf3ixzVDe"
   },
   "source": [
    "cat_correct = []\n",
    "noncat_correct = []\n",
    "cat_wrong = []\n",
    "noncat_wrong = []\n",
    "for label in correct:\n",
    "    if label.split('-')[0] + '-' +label.split('-')[1] in cat_ontology:\n",
    "        cat_correct.append(label)\n",
    "    else:\n",
    "        noncat_correct.append(label)\n",
    "for label in wrong:\n",
    "    if label.split('-')[0] + '-' +label.split('-')[1] in cat_ontology:\n",
    "        cat_wrong.append(label)\n",
    "    else:\n",
    "        noncat_wrong.append(label)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bDiMASytzVDe"
   },
   "source": [
    "print('cat_correct:',len(cat_correct))\n",
    "print('noncat_correct:',len(noncat_correct))\n",
    "print('cat_wrong:',len(cat_wrong))\n",
    "print('noncat_wrong:',len(noncat_wrong))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "i7Dn3Fd3zVDf"
   },
   "source": [
    "from collections import defaultdict"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8-jwnI3fzVDi"
   },
   "source": [
    "cat_correct_dict = defaultdict(int)\n",
    "noncat_correct_dict = defaultdict(int)\n",
    "cat_wrong_dict = defaultdict(int)\n",
    "noncat_wrong_dict = defaultdict(int)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e_qMfW_UzVDi"
   },
   "source": [
    "for cat in cat_correct:\n",
    "    cat_correct_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1\n",
    "for cat in noncat_correct:\n",
    "    noncat_correct_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1    \n",
    "for cat in cat_wrong:\n",
    "    cat_wrong_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1\n",
    "for cat in noncat_wrong:\n",
    "    noncat_wrong_dict[cat.split('-')[0] + '-' +cat.split('-')[1]] +=1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cZCBs0hHzVDk"
   },
   "source": [
    "print('cat 정답률')\n",
    "for cat in cat_ontology:\n",
    "    percent = cat_correct_dict[cat]/(cat_correct_dict[cat] + cat_wrong_dict[cat])*100\n",
    "    print( str(cat), format(percent,\".2f\"),'%', '('+str(cat_correct_dict[cat])+'/'+str(cat_correct_dict[cat] + cat_wrong_dict[cat])+')')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YQX7QO5ozVDk"
   },
   "source": [
    "print('cat 오답률')\n",
    "for cat in cat_ontology:\n",
    "    percent = cat_wrong_dict[cat]/(cat_correct_dict[cat] + cat_wrong_dict[cat])*100\n",
    "    print( str(cat), format(percent,\".2f\"),'%', '('+str(cat_wrong_dict[cat])+'/'+str(cat_correct_dict[cat] + cat_wrong_dict[cat])+')')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "16ugbJ2DzVDl"
   },
   "source": [
    "print('noncat 정답률')\n",
    "for cat in noncat_ontology:\n",
    "    if noncat_correct_dict[cat] ==0:\n",
    "        print(str(cat),' 0.00 %')\n",
    "    else:\n",
    "        percent = noncat_correct_dict[cat]/(noncat_correct_dict[cat] + noncat_wrong_dict[cat])*100\n",
    "        print( str(cat), format(percent,\".2f\"),'%', '('+str(noncat_correct_dict[cat])+'/'+str(noncat_correct_dict[cat] + noncat_wrong_dict[cat])+')')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EMPAo-bRzVDm"
   },
   "source": [
    "print('noncat 오답률')\n",
    "\n",
    "for cat in noncat_ontology:\n",
    "    if noncat_correct_dict[cat] ==0:\n",
    "        print(str(cat),' 0.00 %')\n",
    "    else:\n",
    "        percent = noncat_wrong_dict[cat]/(noncat_correct_dict[cat] + noncat_wrong_dict[cat])*100\n",
    "        print( str(cat), format(percent,\".2f\"),'%', '('+str(noncat_wrong_dict[cat])+'/'+str(noncat_correct_dict[cat] + noncat_wrong_dict[cat])+')')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eJHxkMl1zVDn"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_G0kpEglzVDo"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}