{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0SfPxRakxM-u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "from data_utils import (\n",
    "    load_dataset, \n",
    "    get_examples_from_dialogues, \n",
    "    convert_state_dict, \n",
    "    DSTInputExample, \n",
    "    OpenVocabDSTFeature, \n",
    "    DSTPreprocessor, \n",
    "    WOSDataset)\n",
    "    \n",
    "from inference import inference\n",
    "from evaluation import _evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FByxmqNxM-w"
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "v8_9oFCcxM-w",
    "outputId": "c3e18eb3-f5ec-4296-8f84-702314ee5bb5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6301/6301 [00:00<00:00, 8438.29it/s]\n",
      "100%|██████████| 699/699 [00:00<00:00, 14980.50it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_file = \"/opt/ml/input/data/train_dataset/train_dials.json\"\n",
    "slot_meta = json.load(open(\"/opt/ml/input/data/train_dataset/slot_meta.json\"))\n",
    "ontology = json.load(open(\"/opt/ml/input/data/train_dataset/ontology.json\"))\n",
    "train_data, dev_data, dev_labels = load_dataset(train_data_file)\n",
    "\n",
    "train_examples = get_examples_from_dialogues(train_data,\n",
    "                                             user_first=False,\n",
    "                                             dialogue_level=False)\n",
    "dev_examples = get_examples_from_dialogues(dev_data,\n",
    "                                           user_first=False,\n",
    "                                           dialogue_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L1JyW8ZqxM-x",
    "outputId": "82863af6-14e3-4b62-9ab9-65d096519a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46258\n",
      "4987\n"
     ]
    }
   ],
   "source": [
    "print(len(train_examples))\n",
    "print(len(dev_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf20gZLmxM-y"
   },
   "source": [
    "## TRADE Preprocessor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y80zX3mPxM-y"
   },
   "source": [
    "기존의 GRU 기반의 인코더를 BERT-based Encoder로 바꿀 준비를 합시다.\n",
    "\n",
    "1. 현재 `_convert_example_to_feature`에서는 `max_seq_length`를 핸들하고 있지 않습니다. `input_id`와 `segment_id`가 `max_seq_length`를 넘어가면 좌측부터 truncate시키는 코드를 삽입하세요.\n",
    "\n",
    "2. `recover_state`를 구현해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qw_AmEbHxM-y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TRADEPreprocessor(DSTPreprocessor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        slot_meta,\n",
    "        src_tokenizer,\n",
    "        trg_tokenizer=None,\n",
    "        ontology=None,\n",
    "        max_seq_length=512,\n",
    "    ):\n",
    "        self.slot_meta = slot_meta\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer if trg_tokenizer else src_tokenizer\n",
    "        self.ontology = ontology     \n",
    "        self.gating2id = {\"none\": 0, \"dontcare\": 1, \"ptr\": 2}     \n",
    "        self.id2gating = {v: k for k, v in self.gating2id.items()}\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def _convert_example_to_feature(self, example):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        #context_turns는 t-1까지의 모든 대화, current_turn은 현재 대화 이므로 현재까지의 모든대화를 dialogue context에 넣는다.\n",
    "        #논문에서는 slide window를 이용한다고 하는데 여기서 k값이 문장 전체라고 보면 될 것 같다.\n",
    "        dialogue_context = \" [SEP] \".join(example.context_turns + example.current_turn)\n",
    "        print(dialogue_context)\n",
    "        #tokenizing \n",
    "        input_id = self.src_tokenizer.encode(dialogue_context, add_special_tokens=False)\n",
    "        print(input_id)\n",
    "        \n",
    "        #max_length보다 크면 왼쪽부터 truncating\n",
    "        max_length = self.max_seq_length - 2\n",
    "        \n",
    "        if len(input_id) > max_length:\n",
    "            gap = len(input_id) - max_length\n",
    "            input_id = input_id[gap:]\n",
    "        #cls 토큰 및 sep 토큰 부착\n",
    "        input_id = (\n",
    "            [self.src_tokenizer.cls_token_id]\n",
    "            + input_id\n",
    "            + [self.src_tokenizer.sep_token_id]\n",
    "        )\n",
    "        #segment_id는 문장을 구분해주는 id\n",
    "        segment_id = [0] * len(input_id)\n",
    "        \n",
    "        '''\n",
    "        05.12 15시 기준\n",
    "        gating_id, target_ids의 개념을 현재 잘 이해하지 못하고 있음\n",
    "        공부 후 다시 재도전\n",
    "        '''\n",
    "        \n",
    "        target_ids = []\n",
    "        gating_id = []\n",
    "        #label이 none일수도 있는지 없는경우 list를 할당해준다.\n",
    "        if not example.label:\n",
    "            example.label = []\n",
    "\n",
    "        state = convert_state_dict(example.label)\n",
    "        #print(state)\n",
    "        #print(slot_meta)\n",
    "        for slot in self.slot_meta:\n",
    "            value = state.get(slot, \"none\")\n",
    "            #slot의 value값을 tokenizing\n",
    "            target_id = self.trg_tokenizer.encode(value, add_special_tokens=False) + [\n",
    "                self.trg_tokenizer.sep_token_id\n",
    "            ]\n",
    "            #print(self.trg_tokenizer.decode([21832,11764]),target_id)\n",
    "\n",
    "            target_ids.append(target_id)\n",
    "            #value가 있으면 value, 아니면 ptr이 gating_id로 들어감\n",
    "            gating_id.append(self.gating2id.get(value, self.gating2id[\"ptr\"]))\n",
    "            #print(gating_id)\n",
    "            #gate idx를 gate_id에 input\n",
    "        target_ids = self.pad_ids(target_ids, self.trg_tokenizer.pad_token_id)\n",
    "        #openvacabDSTFeature에는 guid, input_id, segment_id(bert 사용 시), gating_id(gate 사용), target_ids의 정보를 갖고 있음\n",
    "        return OpenVocabDSTFeature(\n",
    "            example.guid, input_id, segment_id, gating_id, target_ids\n",
    "        )\n",
    "    \n",
    "    def convert_examples_to_features(self, examples):\n",
    "        return list(map(self._convert_example_to_feature, examples))\n",
    "\n",
    "    def recover_state(self, gate_list, gen_list):\n",
    "        # problem 2.\n",
    "        # Your code here!\n",
    "        raise Exception('TRADE의 아웃풋을 prediction form으로 바꾸는 코드를 작성하세요!')\n",
    "        \n",
    "        return recovered\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        guids = [b.guid for b in batch]\n",
    "        input_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.input_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        segment_ids = torch.LongTensor(\n",
    "            self.pad_ids([b.segment_id for b in batch], self.src_tokenizer.pad_token_id)\n",
    "        )\n",
    "        input_masks = input_ids.ne(self.src_tokenizer.pad_token_id)\n",
    "\n",
    "        gating_ids = torch.LongTensor([b.gating_id for b in batch])\n",
    "        target_ids = self.pad_id_of_matrix(\n",
    "            [torch.LongTensor(b.target_ids) for b in batch],\n",
    "            self.trg_tokenizer.pad_token_id,\n",
    "        )\n",
    "        return input_ids, segment_ids, input_masks, gating_ids, target_ids, guids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUxTuC2jxM-z"
   },
   "source": [
    "## Convert_Examples_to_Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTrzEfJgxM-0",
    "outputId": "ec44cc34-24a0-42a2-8852-a25d9519d065",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "processor = TRADEPreprocessor(slot_meta, tokenizer, max_seq_length=512)\n",
    "\n",
    "train_features = processor.convert_examples_to_features([train_examples[0]])\n",
    "#dev_features = processor.convert_examples_to_features(dev_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DSTInputExample(guid='snowy-hat-8324:관광_식당_11-0', context_turns=[], current_turn=['', '서울 중앙에 있는 박물관을 찾아주세요'], label=['관광-종류-박물관', '관광-지역-서울 중앙'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1번째 턴의 inpur_id\n",
    "input_id = train_features[0].input_id\n",
    "tokenizer.convert_ids_to_tokens(input_id)\n",
    "train_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SRGlvEDGxM-0",
    "outputId": "f63ed456-9e6f-48b1-d26a-7c7a10646f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46245\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_features))\n",
    "print(len(dev_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJVZN5scxM-0"
   },
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T03:58:02.049196Z",
     "iopub.status.busy": "2021-03-22T03:58:02.048851Z",
     "iopub.status.idle": "2021-03-22T03:58:02.074778Z",
     "shell.execute_reply": "2021-03-22T03:58:02.074001Z",
     "shell.execute_reply.started": "2021-03-22T03:58:02.049167Z"
    },
    "id": "4hkqam7yxM-0"
   },
   "outputs": [],
   "source": [
    "class TRADE(nn.Module):\n",
    "    def __init__(self, config, slot_vocab, slot_meta, pad_idx=0):\n",
    "        super(TRADE, self).__init__()\n",
    "        self.slot_meta = slot_meta\n",
    "        \n",
    "        self.encoder = GRUEncoder(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            1,\n",
    "            config.hidden_dropout_prob,\n",
    "            config.proj_dim,\n",
    "            pad_idx,\n",
    "        )\n",
    "        \n",
    "        self.decoder = SlotGenerator(\n",
    "            config.vocab_size,\n",
    "            config.hidden_size,\n",
    "            config.hidden_dropout_prob,\n",
    "            config.n_gate,\n",
    "            None,\n",
    "            pad_idx,\n",
    "        )\n",
    "        \n",
    "        # init for only subword embedding\n",
    "        self.decoder.set_slot_idx(slot_vocab)\n",
    "        self.tie_weight()\n",
    "\n",
    "        \n",
    "    def tie_weight(self):\n",
    "        self.decoder.embed.weight = self.encoder.embed.weight\n",
    "        if self.decoder.proj_layer:\n",
    "            self.decoder.proj_layer.weight = self.encoder.proj_layer.weight\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask=None, max_len=10, teacher=None):\n",
    "\n",
    "        encoder_outputs, pooled_output = self.encoder(input_ids=input_ids)\n",
    "        all_point_outputs, all_gate_outputs = self.decoder(\n",
    "            input_ids, encoder_outputs, pooled_output.unsqueeze(0), attention_mask, max_len, teacher\n",
    "        )\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs\n",
    "    \n",
    "\n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layer, dropout, proj_dim=None, pad_idx=0):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=pad_idx)\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(d_model, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "\n",
    "        self.d_model = proj_dim if proj_dim else d_model\n",
    "        self.gru = nn.GRU(\n",
    "            self.d_model,\n",
    "            self.d_model,\n",
    "            n_layer,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        mask = input_ids.eq(self.pad_idx).unsqueeze(-1)\n",
    "        x = self.embed(input_ids)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        o, h = self.gru(x)\n",
    "        o = o.masked_fill(mask, 0.0)\n",
    "        output = o[:, :, : self.d_model] + o[:, :, self.d_model :]\n",
    "        hidden = h[0] + h[1]  # n_layer 고려\n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "class SlotGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, hidden_size, dropout, n_gate, proj_dim=None, pad_idx=0\n",
    "    ):\n",
    "        super(SlotGenerator, self).__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed = nn.Embedding(\n",
    "            vocab_size, hidden_size, padding_idx=pad_idx\n",
    "        )  # shared with encoder\n",
    "\n",
    "        if proj_dim:\n",
    "            self.proj_layer = nn.Linear(hidden_size, proj_dim, bias=False)\n",
    "        else:\n",
    "            self.proj_layer = None\n",
    "        self.hidden_size = proj_dim if proj_dim else hidden_size\n",
    "\n",
    "        self.gru = nn.GRU(\n",
    "            self.hidden_size, self.hidden_size, 1, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.n_gate = n_gate\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_gen = nn.Linear(self.hidden_size * 3, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.w_gate = nn.Linear(self.hidden_size, n_gate)\n",
    "\n",
    "    def set_slot_idx(self, slot_vocab_idx):\n",
    "        whole = []\n",
    "        max_length = max(map(len, slot_vocab_idx))\n",
    "        for idx in slot_vocab_idx:\n",
    "            if len(idx) < max_length:\n",
    "                gap = max_length - len(idx)\n",
    "                idx.extend([self.pad_idx] * gap)\n",
    "            whole.append(idx)\n",
    "        self.slot_embed_idx = whole  # torch.LongTensor(whole)\n",
    "\n",
    "    def embedding(self, x):\n",
    "        x = self.embed(x)\n",
    "        if self.proj_layer:\n",
    "            x = self.proj_layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(\n",
    "        self, input_ids, encoder_output, hidden, input_masks, max_len, teacher=None\n",
    "    ):\n",
    "        input_masks = input_masks.ne(1)\n",
    "        # J, slot_meta : key : [domain, slot] ex> LongTensor([1,2])\n",
    "        # J,2\n",
    "        batch_size = encoder_output.size(0)\n",
    "        slot = torch.LongTensor(self.slot_embed_idx).to(input_ids.device)  ##\n",
    "        slot_e = torch.sum(self.embedding(slot), 1)  # J,d\n",
    "        J = slot_e.size(0)\n",
    "\n",
    "        all_point_outputs = torch.zeros(batch_size, J, max_len, self.vocab_size).to(\n",
    "            input_ids.device\n",
    "        )\n",
    "        \n",
    "        # Parallel Decoding\n",
    "        w = slot_e.repeat(batch_size, 1).unsqueeze(1)\n",
    "        hidden = hidden.repeat_interleave(J, dim=1)\n",
    "        encoder_output = encoder_output.repeat_interleave(J, dim=0)\n",
    "        input_ids = input_ids.repeat_interleave(J, dim=0)\n",
    "        input_masks = input_masks.repeat_interleave(J, dim=0)\n",
    "        for k in range(max_len):\n",
    "            w = self.dropout(w)\n",
    "            _, hidden = self.gru(w, hidden)  # 1,B,D\n",
    "\n",
    "            # B,T,D * B,D,1 => B,T\n",
    "            attn_e = torch.bmm(encoder_output, hidden.permute(1, 2, 0))  # B,T,1\n",
    "            attn_e = attn_e.squeeze(-1).masked_fill(input_masks, -1e9)\n",
    "            attn_history = F.softmax(attn_e, -1)  # B,T\n",
    "\n",
    "            if self.proj_layer:\n",
    "                hidden_proj = torch.matmul(hidden, self.proj_layer.weight)\n",
    "            else:\n",
    "                hidden_proj = hidden\n",
    "\n",
    "            # B,D * D,V => B,V\n",
    "            attn_v = torch.matmul(\n",
    "                hidden_proj.squeeze(0), self.embed.weight.transpose(0, 1)\n",
    "            )  # B,V\n",
    "            attn_vocab = F.softmax(attn_v, -1)\n",
    "\n",
    "            # B,1,T * B,T,D => B,1,D\n",
    "            context = torch.bmm(attn_history.unsqueeze(1), encoder_output)  # B,1,D\n",
    "            p_gen = self.sigmoid(\n",
    "                self.w_gen(torch.cat([w, hidden.transpose(0, 1), context], -1))\n",
    "            )  # B,1\n",
    "            p_gen = p_gen.squeeze(-1)\n",
    "\n",
    "            p_context_ptr = torch.zeros_like(attn_vocab).to(input_ids.device)\n",
    "            p_context_ptr.scatter_add_(1, input_ids, attn_history)  # copy B,V\n",
    "            p_final = p_gen * attn_vocab + (1 - p_gen) * p_context_ptr  # B,V\n",
    "            _, w_idx = p_final.max(-1)\n",
    "\n",
    "            if teacher is not None:\n",
    "                w = self.embedding(teacher[:, :, k]).transpose(0, 1).reshape(batch_size * J, 1, -1)\n",
    "            else:\n",
    "                w = self.embedding(w_idx).unsqueeze(1)  # B,1,D\n",
    "            if k == 0:\n",
    "                gated_logit = self.w_gate(context.squeeze(1))  # B,3\n",
    "                all_gate_outputs = gated_logit.view(batch_size, J, self.n_gate)\n",
    "            all_point_outputs[:, :, k, :] = p_final.view(batch_size, J, self.vocab_size)\n",
    "\n",
    "        return all_point_outputs, all_gate_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hhn-hxKkxM-1"
   },
   "source": [
    "# 모델 및 데이터 로더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qp5RRYmxM-2",
    "outputId": "5b69eb58-097b-4246-95fc-b1eedf6fe232"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kyumin/Development/bc_dst/.venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "slot_vocab = []\n",
    "for slot in slot_meta:\n",
    "    slot_vocab.append(\n",
    "        tokenizer.encode(slot.replace('-', ' '),\n",
    "                         add_special_tokens=False)\n",
    "    )\n",
    "    \n",
    "config = BertConfig.from_pretrained('dsksd/bert-ko-small-minimal')\n",
    "config.model_name_or_path = 'dsksd/bert-ko-small-minimal'\n",
    "config.n_gate = len(processor.gating2id)\n",
    "config.proj_dim = None\n",
    "model = TRADE(config, slot_vocab, slot_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T03:58:02.076414Z",
     "iopub.status.busy": "2021-03-22T03:58:02.076171Z",
     "iopub.status.idle": "2021-03-22T03:58:07.655001Z",
     "shell.execute_reply": "2021-03-22T03:58:07.654125Z",
     "shell.execute_reply.started": "2021-03-22T03:58:02.076394Z"
    },
    "id": "CiKK0osexM-2"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = WOSDataset(train_features)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, batch_size=4, sampler=train_sampler, collate_fn=processor.collate_fn)\n",
    "\n",
    "dev_data = WOSDataset(dev_features)\n",
    "dev_sampler = SequentialSampler(dev_data)\n",
    "dev_loader = DataLoader(dev_data, batch_size=8, sampler=dev_sampler, collate_fn=processor.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXqr3ROWxM-2"
   },
   "source": [
    "# Optimizer & Scheduler 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T03:58:07.656475Z",
     "iopub.status.busy": "2021-03-22T03:58:07.656216Z",
     "iopub.status.idle": "2021-03-22T03:58:12.190910Z",
     "shell.execute_reply": "2021-03-22T03:58:12.190106Z",
     "shell.execute_reply.started": "2021-03-22T03:58:07.656453Z"
    },
    "id": "2ws8w9BUxM-2"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "t_total = len(train_loader) * n_epochs\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0.1, num_training_steps=t_total\n",
    ")\n",
    "teacher_forcing = 0.5\n",
    "model.to(device)\n",
    "\n",
    "def masked_cross_entropy_for_value(logits, target, pad_idx=0):\n",
    "    mask = target.ne(pad_idx)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    log_probs_flat = torch.log(logits_flat)\n",
    "    target_flat = target.view(-1, 1)\n",
    "    losses_flat = -torch.gather(log_probs_flat, dim=1, index=target_flat)\n",
    "    losses = losses_flat.view(*target.size())\n",
    "    losses = losses * mask.float()\n",
    "    loss = losses.sum() / (mask.sum().float())\n",
    "    return loss\n",
    "\n",
    "loss_fnc_1 = masked_cross_entropy_for_value  # generation\n",
    "loss_fnc_2 = nn.CrossEntropyLoss()  # gating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s2qvlZ5xM-3"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-22T03:58:12.192122Z",
     "iopub.status.busy": "2021-03-22T03:58:12.191880Z"
    },
    "id": "_nbVwERBxM-3",
    "outputId": "cd7c4a29-34b5-473e-c0b6-5a6ad2fba2a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10] [0/11550] 28.629761\n",
      "[1/10] [0/11550] nan\n",
      "[2/10] [0/11550] nan\n",
      "[3/10] [0/11550] nan\n",
      "[4/10] [0/11550] nan\n",
      "[5/10] [0/11550] nan\n",
      "[6/10] [0/11550] nan\n",
      "[7/10] [0/11550] nan\n",
      "[8/10] [0/11550] nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/631 [00:00<01:04,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] [0/11550] nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 631/631 [01:05<00:00,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'joint_goal_accuracy': 0.018034086405073327, 'turn_slot_accuracy': 0.8214691504822179, 'turn_slot_f1': 0.018034086405073327}\n",
      "joint_goal_accuracy: 0.018034086405073327\n",
      "turn_slot_accuracy: 0.8214691504822179\n",
      "turn_slot_f1: 0.018034086405073327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    batch_loss = []\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        input_ids, segment_ids, input_masks, gating_ids, target_ids, _ = [b.to(device) if not isinstance(b, list) else b for b in batch]\n",
    "        if teacher_forcing > 0.0 and random.random() < teacher_forcing:\n",
    "            tf = target_ids\n",
    "        else:\n",
    "            tf = None\n",
    "\n",
    "        all_point_outputs, all_gate_outputs = model(input_ids, segment_ids, input_masks, target_ids.size(-1))  # gt - length (generation)\n",
    "        loss_1 = loss_fnc_1(all_point_outputs.contiguous(), target_ids.contiguous().view(-1))\n",
    "        loss_2 = loss_fnc_2(all_gate_outputs.contiguous().view(-1, 3), gating_ids.contiguous().view(-1))\n",
    "        loss = loss_1 + loss_2\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        if step % 100 == 0:            \n",
    "            print('[%d/%d] [%d/%d] %f' % (epoch, n_epochs, step, len(train_loader), loss.item()))\n",
    "\n",
    "predictions = inference(model, dev_loader, processor, device)\n",
    "eval_result = _evaluation(predictions, dev_labels, slot_meta)\n",
    "for k, v in eval_result.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y9H1zm7xM-3"
   },
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8BU6k13xM-3"
   },
   "outputs": [],
   "source": [
    "eval_data = json.load(open(f\"/opt/ml/input/data/eval/eval_dials.json\", \"r\"))\n",
    "\n",
    "eval_examples = get_examples_from_dialogues(\n",
    "    eval_data, user_first=False, dialogue_level=False\n",
    ")\n",
    "\n",
    "# Extracting Featrues\n",
    "eval_features = processor.convert_examples_to_features(eval_examples)\n",
    "eval_data = WOSDataset(eval_features)\n",
    "eval_sampler = SequentialSampler(eval_data)\n",
    "eval_loader = DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=8,\n",
    "    sampler=eval_sampler,\n",
    "    collate_fn=processor.collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEUIHCcSxM-4"
   },
   "outputs": [],
   "source": [
    "predictions = inference(model, eval_loader, processor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KjwNsGDkxM-4"
   },
   "outputs": [],
   "source": [
    "json.dumps(predictions, open('predictions.csv', 'w'), indent=2, ensure_ascii=False) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TRADE-preprocessor.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
